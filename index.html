<!DOCTYPE html>
<html lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no">
<meta name="author" content="ID喵">


    
    


<meta property="og:type" content="website">
<meta property="og:title" content="ID喵">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="ID喵">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ID喵">

<link rel="apple-touch-icon" href="/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="ID喵" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">


    <style> .article { opacity: 0;} </style>


<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>ID喵</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: true,
        isPost: false,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: 
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head></html>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/langya.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">ID喵</a></h1>
        </hgroup>

        
        <p class="header-subtitle">喵了个喵，我又遇到瓶颈了...</p>
        

        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/archives/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="/xiaoran737@163.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="https://github.com/ValjeanShaw" title="GitHub"></a>
                            
                                <a class="fa 博客园" href="https://www.cnblogs.com/valjeanshaw/" title="博客园"></a>
                            
                                <a class="fa 掘金" href="https://juejin.im/user/5d5bd7106fb9a06b0c08695f" title="掘金"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/concurrent/">concurrent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">ID喵</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/langya.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">ID喵</a></h1>
            </hgroup>
            
            <p class="header-subtitle">喵了个喵，我又遇到瓶颈了...</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/archives/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="/xiaoran737@163.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="https://github.com/ValjeanShaw" title="GitHub"></a>
                            
                                <a class="fa 博客园" target="_blank" href="https://www.cnblogs.com/valjeanshaw/" title="博客园"></a>
                            
                                <a class="fa 掘金" target="_blank" href="https://juejin.im/user/5d5bd7106fb9a06b0c08695f" title="掘金"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap">
  
    <article id="post-Hadoop系列（五）Hadoop三大核心之HDFS-读写流程" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/" class="article-date">
      <time datetime="2019-09-08T07:31:34.000Z" itemprop="datePublished">2019-09-08</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/">Hadoop系列（五）Hadoop三大核心之HDFS 读写流程</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<p>首先，再回顾一下HDFS的架构图</p>
<p><img src="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/image-20190908154045344.png" alt="image-20190908154045344"></p>
<h2 id="HDFS写数据流程"><a href="#HDFS写数据流程" class="headerlink" title="HDFS写数据流程"></a>HDFS写数据流程</h2><p><img src="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/image-20190908154424852.png" alt="image-20190908154424852"></p>
<ol>
<li>客户端发送请求，调用DistributedFileSystem API的create方法去请求namenode，并告诉namenode上传文件的文件名、文件大小、文件拥有者。</li>
<li>namenode根据以上信息算出文件需要切成多少块block，以及block要存放在哪个datanode上，并将这些信息返回给客户端。</li>
<li>客户端调用FSDataInputStream API的write方法首先将其中一个block写在datanode上。</li>
<li>每一个block多个副本（默认3个），由已经上传了block的datanode产生新的线程，按照放置副本规则往其它datanode写副本。（并不是由客户端分别往3个datanode上写3份，这样的优势就是快。）</li>
<li>写完后返回给客户端一个信息，然后客户端在将信息反馈给namenode。更新元数据。</li>
</ol>
<h2 id="HDFS读流程"><a href="#HDFS读流程" class="headerlink" title="HDFS读流程"></a>HDFS读流程</h2><p><img src="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/image-20190908155152510.png" alt="image-20190908155152510"></p>
<ol>
<li>客户端通过调用FileSystem对象中的open()方法来读取需要的数据</li>
<li>DistributedFileSystem会通过RPC协议调用NameNode来查找文件块所在的位置</li>
</ol>
<blockquote>
<p><strong>NameNode只会返回所调用文件中开始的几个块而不是全部返回。对于每个返回的块，都包含块所在的DataNode的地址。随后，这些返回的DataNode会按照Hadoop集群的拓扑结构得出客户端的距离，然后再进行排序。如果客户端本身就是DataNode，那么它就从本地读取文件。</strong>其次，DistributedFileSystem会向客户端返回一个支持定位的输入流对象FSDataInputStream，用于给客户端读取数据。FSDataInputStream包含一个DFSInputStream对象，这个对象来管理DataNode和NameNode之间的IO</p>
</blockquote>
<ol start="3">
<li><p>当以上步骤完成时，客户端便会在这个输入流上调用read()方法</p>
</li>
<li><p>DFSInputStream对象中包含文件开始部分数据块所在的DataNode地址，首先它会连接文件第一个块最近的DataNode，随后在数据流中重复调用read方法，直到这个块读完为止。</p>
</li>
<li><p>当第一个块读取完毕时，DFSInputStream会关闭连接，并查找存储下一个数据块距离客户端最近的DataNode，以上这些步骤对客户端来说都是透明的。</p>
</li>
<li><p>当完成所有块的读取时，客户端则会在DFSInputStream中调用close()方法。</p>
</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-序列化" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/05/序列化/" class="article-date">
      <time datetime="2019-09-05T15:55:22.000Z" itemprop="datePublished">2019-09-05</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/05/序列化/">序列化</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="一、序列化和反序列化的定义和场景"><a href="#一、序列化和反序列化的定义和场景" class="headerlink" title="一、序列化和反序列化的定义和场景"></a>一、序列化和反序列化的定义和场景</h2><p>序列化：将对象写入到IO流中</p>
<p>反序列化：从IO流中恢复对象</p>
<p>序列化机制将实现序列化的Java对象转化为字节数组序列。可以使对象可以脱离程序而独立运行</p>
<p>场景和要求：保存到磁盘；在网络中传输。要保存到磁盘和在远程传输的java对象要求都必须是可序列化的。</p>
<p><img src="/2019/09/05/序列化/image-20190907150807138.png" alt="image-20190907150807138"></p>
<h2 id="二、序列化和反序列化的java实现"><a href="#二、序列化和反序列化的java实现" class="headerlink" title="二、序列化和反序列化的java实现"></a>二、序列化和反序列化的java实现</h2><h3 id="Serializable接口"><a href="#Serializable接口" class="headerlink" title="Serializable接口"></a>Serializable接口</h3><p>一个标记接口，不用实现任何方法。一旦实现了此接口，该类的对象就是可序列化的。</p>
<h4 id="序列化步骤"><a href="#序列化步骤" class="headerlink" title="序列化步骤"></a>序列化步骤</h4><p>1 创建ObjectOutputStream输出流；2 调用ObjectOutputStream对象的writeObject输出可序列化对象。</p>
<p>若对象不是序列化对象，序列化是将抛出 NotSerializableException 异常</p>
<h4 id="反序列化步骤"><a href="#反序列化步骤" class="headerlink" title="反序列化步骤"></a>反序列化步骤</h4><p>1 创建ObjectInputStream输入流；2 调用ObjectInputStream对象的readObject()得到可序列化对象</p>
<p>demo:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">People</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> String city;</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCity</span><span class="params">(String city)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.city = city;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        People people = <span class="keyword">new</span> People();</span><br><span class="line">        people.setCity(<span class="string">"成都"</span>);</span><br><span class="line">        people.setName(<span class="string">"假老练"</span>);</span><br><span class="line">        People people1 = <span class="keyword">new</span> People();</span><br><span class="line">        people1.setCity(<span class="string">"北京"</span>);</span><br><span class="line">        people1.setName(<span class="string">"风车车"</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            FileOutputStream fileOutputStream = <span class="keyword">new</span> FileOutputStream(<span class="string">"object.txt"</span>);</span><br><span class="line">            ObjectOutputStream os = <span class="keyword">new</span> ObjectOutputStream(fileOutputStream);</span><br><span class="line">            os.writeObject(people);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            FileInputStream fileInputStream = <span class="keyword">new</span> FileInputStream(<span class="string">"object.txt"</span>);</span><br><span class="line">            ObjectInputStream os = <span class="keyword">new</span> ObjectInputStream(fileInputStream);</span><br><span class="line">            People peopleResult = (People) os.readObject();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>如果需要序列化的类的属性含有非基本数据类型和String类型，即引用类型，那么该引用类型也比如可序列化</strong>。否则依然会抛出 NotSerializableException 异常</p>
<h4 id="serialVersionUID的作用"><a href="#serialVersionUID的作用" class="headerlink" title="serialVersionUID的作用"></a>serialVersionUID的作用</h4><p>Java 的序列化，通过在运行时判断类的serialVersionUID来验证版本一致性。</p>
<p>在进行反序列化时，JVM 会把传来的字节流中的serialVersionUID与本地相应实体（类）的serialVersionUID进行比较，如果相同就认为是一致的，可以进行反序列化，否则就会出现序列化版本不一致的异常。实测如果id一致，属性发生较小变化，对象也会创建出来，并将属性按属性名对号入座。</p>
<p> 当实现序列化的时候，建议显式定义serialVersionUID，若不显式定义 serialVersionUID 的值，Java 会根据类细节自动生成 serialVersionUID 的值。可能造成以下两个问题。1.如果对类的源代码作了修改，再重新编译，新生成的类文件的serialVersionUID的取值有可能也会发生变化。2.类的serialVersionUID的默认值完全依赖于Java编译器的实现，对于同一个类，用不同的Java编译器编译，也有可能会导致不同的serialVersionUID，即不同机器或不同版本jdk反序列化可能失败。</p>
<p>##总计 </p>
<ol>
<li>序列化是将对象写入到IO字节流，反序列化是从IO字节流中恢复对象</li>
<li>序列化的两个主要作用是用来存储和网络传输</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/">java</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-进程，线程与多核，多cpu之间的关系" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/02/进程，线程与多核，多cpu之间的关系/" class="article-date">
      <time datetime="2019-09-02T02:55:41.000Z" itemprop="datePublished">2019-09-02</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/02/进程，线程与多核，多cpu之间的关系/">进程，线程与多核，多cpu之间的关系</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="cpu架构和工作原理"><a href="#cpu架构和工作原理" class="headerlink" title="cpu架构和工作原理"></a>cpu架构和工作原理</h2><p>计算机有5大基本组成部分，运算器，控制器，存储器，输入和输出。运算器和控制器封装到一起，加上寄存器组和cpu内部总线构成中央处理器（CPU）。cpu的根本任务，就是执行指令，对计算机来说，都是0，1组成的序列，cpu从逻辑上可以划分为3个模块：控制单元、运算单元和存储单元。这三个部分由cpu总线连接起来。</p>
<p><img src="/2019/09/02/进程，线程与多核，多cpu之间的关系/image-20190902202929616.png" alt="image-20190902202929616"></p>
<p>CPU的运行原理就是：控制单元在时序脉冲的作用下，将指令计数器里所指向的指令地址(这个地址是在内存里的)送到地址总线上去，然后CPU将这个地址里的指令读到指令寄存器进行译码。对于执行指令过程中所需要用到的数据，会将数据地址也送到地址总线，然后CPU把数据读到CPU的内部存储单元(就是内部寄存器)暂存起来，最后命令运算单元对数据进行处理加工。周而复始，一直这样执行下去。</p>
<h2 id="多核cpu和多cpu"><a href="#多核cpu和多cpu" class="headerlink" title="多核cpu和多cpu"></a>多核cpu和多cpu</h2><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>多个物理CPU，CPU通过总线进行通信，效率比较低。</p>
<p><img src="/2019/09/02/进程，线程与多核，多cpu之间的关系/image-20190904121329148.png" alt="image-20190904121329148"></p>
<p>多核CPU，不同的核通过L2 cache进行通信，存储和外设通过总线与CPU通信</p>
<p><img src="/2019/09/02/进程，线程与多核，多cpu之间的关系/image-20190904121349591.png" alt="image-20190904121349591"></p>
<h3 id="cpu的缓存"><a href="#cpu的缓存" class="headerlink" title="cpu的缓存"></a>cpu的缓存</h3><p>CPU缓存是位于CPU与内存之间的临时数据交换器，它的容量比内存小的多但是交换速度却比内存要快得多。CPU缓存一般直接跟CPU芯片集成或位于主板总线互连的独立芯片上。</p>
<p><img src="/2019/09/02/进程，线程与多核，多cpu之间的关系/image-20190905092214302.png" alt="image-20190905092214302"></p>
<p>随着多核CPU的发展，CPU缓存通常分成了三个级别：<code>L1</code>，<code>L2</code>，<code>L3</code>。级别越小越接近CPU，所以速度也更快，同时也代表着容量越小。L1 是最接近CPU的, 它容量最小（例如：<code>32K</code>），速度最快，每个核上都有一个 L1 缓存，L1 缓存每个核上其实有两个 L1 缓存, 一个用于存数据的 L1d Cache（Data Cache），一个用于存指令的 L1i Cache（Instruction Cache）。L2 缓存 更大一些（例如：<code>256K</code>），速度要慢一些, 一般情况下每个核上都有一个独立的L2 缓存; L3 缓存是三级缓存中最大的一级（例如3MB），同时也是最慢的一级, 在同一个CPU插槽之间的核共享一个 L3 缓存。</p>
<p>读取数据过程。就像数据库缓存一样，首先在最快的缓存中找数据，如果缓存没有命中(Cache miss) 则往下一级找, 直到三级缓存都找不到时，向内存要数据。一次次地未命中，代表取数据消耗的时间越长。</p>
<p>计算过程。程序以及数据被加载到主内存；指令和数据被加载到CPU的高速缓；CPU执行指令，把结果写到高速缓存；高速缓存中的数据写回主内存</p>
<h2 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h2><p>进程是程序的一次执行，一个程序有至少一个进程，是<code>资源分配的最小单位</code>，资源分配包括cpu、内存、磁盘IO等。线程是<code>程序执行的最小单位</code>,一个进程有至少一个线程。</p>
<h2 id="进程和线程在多核cpu，多cpu中的运行关系"><a href="#进程和线程在多核cpu，多cpu中的运行关系" class="headerlink" title="进程和线程在多核cpu，多cpu中的运行关系"></a>进程和线程在多核cpu，多cpu中的运行关系</h2><p>多cpu的运行，是针对进程的运行状态来说的；多核cpu的运行，是针对线程的运行状态来说的。</p>
<p>操作系统会拆分CPU为一段段时间的运行片，轮流分配给不同的程序。对于多cpu，多个进程可以并行在多个cpu中计算，当然也会存在进程切换；对于单cpu，多个进程在这个单cpu中是并发运行，根据时间片读取上下文+执行程序+保存上下文。同一个进程同一时间段只能在一个cpu中运行，如果进程数小于cpu数，那么未使用的cpu将会空闲。</p>
<p>对于多核cpu，进程中的多线程并行执行，执行过程中存在线程切换，线程切换开销较小。对于单核cpu，多线程在单cpu中并发执行，根据时间片切换线程。同一个线程同一时间段只能在一个cpu内核中运行，如果线程数小于cpu内核数，那么将有多余的内核空闲。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>1 单CPU中进程只能是并发，多CPU计算机中进程可以并行。</p>
<p>2单CPU单核中线程只能并发，单CPU多核中线程可以并行。</p>
<p>3 无论是并发还是并行，使用者来看，看到的是多进程，多线程。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/concurrent/">concurrent</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop系列（四）Hadoop三大核心之HDFS-Java-API" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/01/Hadoop系列（四）Hadoop三大核心之HDFS-Java-API/" class="article-date">
      <time datetime="2019-09-01T08:51:48.000Z" itemprop="datePublished">2019-09-01</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/01/Hadoop系列（四）Hadoop三大核心之HDFS-Java-API/">Hadoop系列（四）Hadoop三大核心之HDFS Java API</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<p>HDFS 设计的主要目的是对海量数据进行存储，也就是说在其上能够存储很大量的文件。</p>
<p>HDFS 将这些文件分割之后，存储在不同的 DataNode 上，HDFS 提供了通过Java API 对 HDFS 里面的文件进行操作的功能，数据块在 DataNode 上的存放位置，对于开发者来说是透明的。</p>
<p>使用 Java API 可以完成对 HDFS 的各种操作，如新建文件、删除文件、读取文件内容等。下面将介绍 HDFS 常用的 Java API 及其编程实例。</p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><ul>
<li>Configuration   封装了客户端或者服务器的配置</li>
<li>FileSystem  文件系统对象，用该对象的方法来对文件进行操作</li>
<li>FileStatus   用于向客户端展示系统中文件和目录的元数据</li>
<li>FSDatalnputStream   HDFS 中的输入流，用于读取 Hadoop 文件</li>
<li>FSDataOutputStream   HDFS 中的输出流，用于写 Hadoop 文件</li>
<li>Path   用于表示 Hadoop 文件系统中的文件或者目录的路径</li>
</ul>
<h2 id="具体操作"><a href="#具体操作" class="headerlink" title="具体操作"></a>具体操作</h2><ol>
<li>导入maven依赖包</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>初始化配置</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Configuration conf;</span><br><span class="line">FileSystem fileSystem;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HdfsAPI</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    conf.set(<span class="string">"dfs.replication"</span>, <span class="string">"2"</span>);</span><br><span class="line">    conf.set(<span class="string">"dfs.blocksize"</span>, <span class="string">"128m"</span>);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        fileSystem = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://$&#123;NameNode&#125;:9000"</span>), conf, <span class="string">"hadoop"</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>get文件   get</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testGet</span><span class="params">()</span> <span class="keyword">throws</span> IllegalArgumentException, IOException </span>&#123;</span><br><span class="line">    fileSystem.copyToLocalFile(<span class="keyword">new</span> Path(<span class="string">"/output/part.txt"</span>), <span class="keyword">new</span> Path(<span class="string">"~/Downloads"</span>));</span><br><span class="line">    fileSystem.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>获取文件信息   ls</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testLs</span><span class="params">()</span> <span class="keyword">throws</span> IllegalArgumentException, IOException </span>&#123;</span><br><span class="line">    RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fileSystem.listFiles(<span class="keyword">new</span> Path(<span class="string">"/"</span>), <span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">while</span> (listFiles.hasNext()) &#123;</span><br><span class="line">        LocatedFileStatus status = listFiles.next();</span><br><span class="line">        System.out.println(<span class="string">"路径："</span> + status.getPath());</span><br><span class="line">        System.out.println(<span class="string">"块大小："</span> + status.getBlockSize());</span><br><span class="line">        System.out.println(<span class="string">"文件长度："</span> + status.getLen());</span><br><span class="line">        System.out.println(<span class="string">"副本数:"</span> + status.getReplication());</span><br><span class="line">        System.out.println(<span class="string">"块的位置信息："</span> + Arrays.toString(status.getBlockLocations()) + <span class="string">"\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    fileSystem.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>创建目录，多级目录    mkdir</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testMkdir</span><span class="params">()</span> <span class="keyword">throws</span> IllegalArgumentException, IOException </span>&#123;</span><br><span class="line">    fileSystem.mkdirs(<span class="keyword">new</span> Path(<span class="string">"/output/test/testmk"</span>));</span><br><span class="line">    fileSystem.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>删除文件，目录  rm</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testDeldir</span><span class="params">()</span> <span class="keyword">throws</span> IllegalArgumentException, IOException </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> delete = fileSystem.delete(<span class="keyword">new</span> Path(<span class="string">"/output/test/testmk"</span>), <span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">if</span> (delete) &#123;</span><br><span class="line">        System.out.println(<span class="string">"文件已经删除"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    fileSystem.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="7">
<li>读取hdfs文件内容</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testReadData</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    FSDataInputStream in = fileSystem.open(<span class="keyword">new</span> Path(<span class="string">"/test.txt"</span>));<span class="comment">//hdfs自带流打开文件</span></span><br><span class="line">    BufferedReader br = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(in, <span class="string">"utf-8"</span>));<span class="comment">//读入流并放在缓冲区</span></span><br><span class="line">    String line = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">while</span> ((line = br.readLine()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">        System.out.println(line);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    in.close();</span><br><span class="line">    br.close();</span><br><span class="line">    fileSystem.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="8">
<li>读取hdfs中文件中指定偏移的内容</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testRandomReadData</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    FSDataInputStream in = fileSystem.open(<span class="keyword">new</span> Path(<span class="string">"/test.txt"</span>));</span><br><span class="line">    in.seek(<span class="number">12</span>);<span class="comment">//定位到12位置开始读</span></span><br><span class="line">    <span class="keyword">byte</span>[] buf = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">16</span>];<span class="comment">//往后读取16个位</span></span><br><span class="line">    in.read(buf);<span class="comment">//ba流读到buf中</span></span><br><span class="line">    System.out.println(<span class="keyword">new</span> String(buf));</span><br><span class="line">    in.close();</span><br><span class="line">    fileSystem.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="9">
<li>数据写到hdfs中</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testWriteData</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    FSDataOutputStream out = fileSystem.create(<span class="keyword">new</span> Path(<span class="string">"/yy.jpg"</span>), <span class="keyword">false</span>);</span><br><span class="line">    FileInputStream in = <span class="keyword">new</span> FileInputStream(<span class="string">"~/Download/wechatpic_20190309221605.jpg"</span>);</span><br><span class="line">    <span class="keyword">byte</span>[] buf = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">    <span class="keyword">int</span> read = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> ((read = in.read(buf)) != -<span class="number">1</span>) &#123;</span><br><span class="line">        out.write(buf, <span class="number">0</span>, read);</span><br><span class="line">    &#125;</span><br><span class="line">    out.close();</span><br><span class="line">    fileSystem.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop系列（三）Hadoop三大核心之HDFS-shell常用命令" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/08/29/Hadoop系列（三）Hadoop三大核心之HDFS-shell常用命令/" class="article-date">
      <time datetime="2019-08-29T15:51:48.000Z" itemprop="datePublished">2019-08-29</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/08/29/Hadoop系列（三）Hadoop三大核心之HDFS-shell常用命令/">Hadoop系列（三）Hadoop三大核心之HDFS shell常用命令</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="HDFS常用命令"><a href="#HDFS常用命令" class="headerlink" title="HDFS常用命令"></a>HDFS常用命令</h2><h3 id="help-查看所有命令"><a href="#help-查看所有命令" class="headerlink" title="help 查看所有命令"></a>help 查看所有命令</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs help</code></p>
<h3 id="查看路径文件"><a href="#查看路径文件" class="headerlink" title="查看路径文件"></a>查看路径文件</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -ls /</code></p>
<h3 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -mkdir /test</code></p>
<h3 id="创建多级文件夹"><a href="#创建多级文件夹" class="headerlink" title="创建多级文件夹"></a>创建多级文件夹</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -mkdir -p /test/test1/test2</code></p>
<h3 id="查看指定目录下和子目录下所有文件"><a href="#查看指定目录下和子目录下所有文件" class="headerlink" title="查看指定目录下和子目录下所有文件"></a>查看指定目录下和子目录下所有文件</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -ls -R /test</code></p>
<h3 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -put part.txt /test</code></p>
<p>or</p>
<p><code>[172.23.7.9:hadoop]$ hadoop fs -copyFromLocal part.txt /test</code></p>
<h3 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -get /test/part.txt ~/test</code></p>
<p>or</p>
<p><code>[172.23.7.9:hadoop]$ hadoop fs -copyToLocal /test/part.txt ~/test</code></p>
<h3 id="合并下载"><a href="#合并下载" class="headerlink" title="合并下载"></a>合并下载</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -getmerge /test/part0.txt /test/part1.txt ./temp.txt</code></p>
<h3 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -cp /test/part.txt /output</code></p>
<h3 id="移动"><a href="#移动" class="headerlink" title="移动"></a>移动</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -mv /test/part.txt /output</code></p>
<h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -rm /test/part.txt</code></p>
<p>强制删除</p>
<p><code>[172.23.7.9:hadoop]$ hadoop fs -rm -r /test/part.txt</code></p>
<h3 id="查看文件内容"><a href="#查看文件内容" class="headerlink" title="查看文件内容"></a>查看文件内容</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -cat /test/part.txt</code></p>
<h3 id="显示文件大小"><a href="#显示文件大小" class="headerlink" title="显示文件大小"></a>显示文件大小</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -du -h /test/part.txt</code></p>
<h3 id="test"><a href="#test" class="headerlink" title="test"></a>test</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -test -[ezd] /test/part.txt</code></p>
<p>选项：<br>-e 检查文件是否存在。如果存在则返回0。<br>-z 检查文件是否是0字节。如果是则返回0。<br>-d 如果路径是个目录，则返回1，否则返回0。</p>
<h2 id="web界面"><a href="#web界面" class="headerlink" title="web界面"></a>web界面</h2><p><code>http://xx.xx.xx.xx:9870/explorer.html#/</code></p>
<p><img src="/2019/08/29/Hadoop系列（三）Hadoop三大核心之HDFS-shell常用命令/image-20190830010745946.png" alt="image-20190830010745946"></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop系列（二）Hadoop三个核心之HDFS" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/08/25/Hadoop系列（二）Hadoop三个核心之HDFS/" class="article-date">
      <time datetime="2019-08-25T14:27:28.000Z" itemprop="datePublished">2019-08-25</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/08/25/Hadoop系列（二）Hadoop三个核心之HDFS/">Hadoop系列（二）Hadoop三大核心之HDFS基础</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<p>针对海量数据，核心问题始终是计算和存储。当数据集的大小超过一台独立物理计算机的存储能力时，就有必要对它进行分区并存储到多台机器上。跨机器存储的文件系统就被成为分布式文件系统。分布式系统架构于网络之上，势必引入网络编程的复杂性，如何实现容忍节点故障但不丢失数据，是HDFS的重要挑战。</p>
<h2 id="hdfs基础"><a href="#hdfs基础" class="headerlink" title="hdfs基础"></a>hdfs基础</h2><p>Hadoop 自带HDFS分布式文件系统：Hadoop Distributed Filesystem。也简称DFS。主要用来解决海量数据的存储问题。</p>
<p>HDFS有以下两点特性</p>
<ul>
<li>文件系统：用于存储文件，通过统一目录树定位</li>
<li>分布式：很多机器共同支撑其功能</li>
</ul>
<h3 id="重要概念"><a href="#重要概念" class="headerlink" title="重要概念"></a>重要概念</h3><h4 id="数据块"><a href="#数据块" class="headerlink" title="数据块"></a>数据块</h4><p>和一般的文件系统一样，HDFS也有块（block）的概念，HDFS上的文件也被划分为块大小的多个分块作为独立的存储单元。</p>
<p>Hadoop 1.x 默认大小为64MB, 2.x和3.x均为128MB。具体指定版本的默认值，可参见官网<a href="http://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Blocks" target="_blank" rel="noopener">块的定义</a>。HDFS的块比磁盘的块大，是为了最小化寻址开销，减少寻址定位所需时间。</p>
<p>与磁盘文件系统不一样的是*<em>HDFS中小于一个块大小的文件不会占据整个块的空间 *</em>例：当一个1MB的文件存储在一个128MB的块中时，文件只使用1MB的磁盘空间，而不是128MB。当一个150M的文件要存储到HDFS中，将会拆分成2个块，大小分别是128M、22M。</p>
<p>设置数据块的好处：</p>
<p>（1）一个文件的大小可以大于集群任意节点磁盘的容量</p>
<p>（2）容易对数据进行备份，提高容错能力，块丢失可快速从其它节点复制</p>
<p>（3）使用抽象块概念而非整个文件作为存储单元，大大简化存储子系统的设计</p>
<p>HDFS集群有两类节点以管理节点-工作节点的方式运行。即NameNode和DataNode。</p>
<h4 id="NameNode（NN）"><a href="#NameNode（NN）" class="headerlink" title="NameNode（NN）"></a>NameNode（NN）</h4><p>文件系统的管理节点。管理文件系统的命名空间，维护着文本系统树及整棵树内所有文件和目录。基于内存存储，在内存中保存着文件系统每个文件和每个数据块的引用关系以及块信息等。文件目录在NameNode重启后，需要重建。</p>
<p>功能：</p>
<ul>
<li>接收客户端读写服务</li>
<li>收集DataNode汇报的Block列表信息</li>
</ul>
<h4 id="DataNode（DN）"><a href="#DataNode（DN）" class="headerlink" title="DataNode（DN）"></a>DataNode（DN）</h4><p>文件系统的工作节点，多个节点共同工作。本地磁盘目录存储数据，文件形式。</p>
<p>功能：</p>
<ul>
<li>文件形式存储数据（Block）</li>
<li>存储Block的元数据信息文件 （md5）</li>
<li>启动时向NameNode汇报block信息</li>
<li>与NameNode保持心跳连接（3s/次）</li>
</ul>
<p>NameNode虽然以内存方式存储，但是NameNode也会在适当时候持久化两类文件到磁盘。</p>
<ul>
<li>fsimage：NameNode启动时对整个文件系统的快照</li>
<li>edit logs：NameNode启动后，对文件系统的改动序列</li>
</ul>
<p><img src="/2019/08/25/Hadoop系列（二）Hadoop三个核心之HDFS/image-20190827232356723.png" alt="image-20190827232356723"></p>
<p>只有在NameNode重启时，edit logs才会合并到fsimage文件中，从而得到一个文件系统的最新快照。但是在产品集群中NameNode是很少重启的，这也意味着当NameNode运行了很长时间后，edit logs文件会变得很大。这会引发以下严重问题：1.edit logs文件会变的很大，不容易管理；2.重启会花费很长时间，因为有很多改动，可能经历好几个小时甚至几十个小时，这是不能容忍的。</p>
<h4 id="Secondary-NameNode-SNN"><a href="#Secondary-NameNode-SNN" class="headerlink" title="Secondary NameNode   (SNN)"></a>Secondary NameNode   (SNN)</h4><p>SecondaryNameNode就是来帮助解决上述问题的，职责是帮助NN合并edits log成fsimage，减少NameNode启动时间</p>
<p>SNN 合并edits触发条件：<br>1.定期触发。默认一小时。<br>2.时间未到的情况，edits log大小超过容量也会触发。默认 64M。</p>
<p>配置文件core-site.xml  可设置时间间隔（fs.checkpoint.period ）和edits log容量（fs.checkpoint.size）。</p>
<p><img src="/2019/08/25/Hadoop系列（二）Hadoop三个核心之HDFS/5D3FAC2F-F9B2-4F08-B5EA-68771B0BA0F8.png" alt="5D3FAC2F-F9B2-4F08-B5EA-68771B0BA0F8"></p>
<h2 id="Hadoop-特点"><a href="#Hadoop-特点" class="headerlink" title="Hadoop 特点"></a>Hadoop 特点</h2><p>HDFS也是按照Master和Slave的结构。分NameNode、SecondaryNameNode、DataNode这几个角色。</p>
<p><img src="/2019/08/25/Hadoop系列（二）Hadoop三个核心之HDFS/1228818-20180308190320147-1328604927.png" alt="img"></p>
<p>因其架构方案，拥有很多特点：<br>        保存多个副本，且提供容错机制，副本丢失或宕机自动恢复（默认存3份）。<br>　　可运行在廉价的机器上<br>　　适合大数据的处理。HDFS默认会将文件分割成block。然后将block按键值对存储在HDFS上，并将键值对的映射存到内存中。</p>
<p>当然HDFS也有其局限性：<br>1.低延时数据访问。在用户交互性的应用中，应用需要在ms或者几个s的时间内得到响应。由于HDFS为高吞吐率做了设计，也因此牺牲了快速响应。对于低延时的应用，可以考虑使用HBase或者Cassandra。<br>2.大量的小文件。标准的HDFS数据块的大小是64M，存储小文件并不会浪费实际的存储空间，但是无疑会增加了在NameNode上的元数据，大量的小文件会影响整个集群的性能。<br>3.多用户写入，修改文件。HDFS的文件只能有一个写入者，而且写操作只能在文件结尾以追加的方式进行。它不支持多个写入者，也不支持在文件写入后，对文件的任意位置的修改。<br>但是在大数据领域，分析的是已经存在的数据，这些数据一旦产生就不会修改，因此，HDFS的这些特性和设计局限也就很容易理解了。HDFS为大数据领域的数据分析，提供了非常重要而且十分基础的文件存储功能。</p>
<h2 id="Hadoop-HA"><a href="#Hadoop-HA" class="headerlink" title="Hadoop HA"></a>Hadoop HA</h2><h4 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h4><ol>
<li>冗余备份<br>每个文件存储成一系列数据块（Block）。为了容错，文件的所有数据块都会有副本（副本数量即复制因子，可配置）（dfs.replication）</li>
<li>副本存放<br>采用机架感知（Rak-aware）的策略来改进数据的可靠性、高可用和网络带宽的利用率</li>
<li>心跳检测<br>NameNode周期性地从集群中的每一个DataNode接受心跳包和块报告，收到心跳包说明该DataNode工作正常</li>
<li>安全模式<br>系统启动时，NameNode会进入一个安全模式。此时不会出现数据块的写操作。</li>
<li>数据完整性检测<br>HDFS客户端软件实现了对HDFS文件内容的校验和（Checksum）检查（dfs.bytes-per-checksum）。</li>
</ol>
<h4 id="单点故障问题"><a href="#单点故障问题" class="headerlink" title="单点故障问题"></a>单点故障问题</h4><p>因为NameNode部署为单点失效，存在单点故障问题，当NameNode，那么客户端或MapReduce作业均无法读写查看文件。注意HDFS已有存储不会丢失。</p>
<p>解决方案：</p>
<p>启动一个拥有文件系统元数据的新NameNode（这个一般不采用，因为复制元数据非常耗时间）<br>配置一对活动-备用（Active-Sandby）NameNode，活动NameNode失效时，备用NameNode立即接管，用户不会有明显中断感觉。<br>　　　　共享编辑日志文件（借助NFS、zookeeper等）<br>　　　　DataNode同时向两个NameNode汇报数据块信息<br>　　　　客户端采用特定机制处理 NameNode失效问题，该机制对用户透明</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop开篇" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/08/24/Hadoop开篇/" class="article-date">
      <time datetime="2019-08-23T16:08:08.000Z" itemprop="datePublished">2019-08-24</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/08/24/Hadoop开篇/">Hadoop系列（一）开篇简介</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<p>谁说大象不会跳舞</p>
<h2 id="Hadoop是什么"><a href="#Hadoop是什么" class="headerlink" title="Hadoop是什么"></a>Hadoop是什么</h2><p>Hadoop的官网：<a href="http://hadoop.apache.org/" target="_blank" rel="noopener">http://hadoop.apache.org/</a></p>
<p>官网定义：The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models.</p>
<p>Hadoop： 适合大数据的分布式存储和计算平台</p>
<p>现为Apache顶级开源项目，Hadoop不是指具体一个框架或者组件，它是Apache软件基金会下用Java语言开发的一个开源分布式计算平台。实现在大量计算机组成的集群中对海量数据进行分布式计算，适合大数据的分布式存储和计算平台。</p>
<p>举个简单例子：假如说你有一个篮子水果，你想知道苹果和梨的数量是多少，那么只要一个一个数就可以知道有多少了。如果你有一个集装箱水果，这时候就需要很多人同时帮你数了，这相当于多进程或多线程。如果你很多个集装箱的水果，这时就需要分布式计算了，也就是Hadoop。Hadoopd之所谓会诞生，主要是由于进入到大数据时代，计算机需要处理的数据量太过庞大。这时就需要将这些庞大数据切割分配到N台计算机进行处理。当大量信息被分配到不同计算机进行处理时，要确保最终得到的结果正确就需要对这些分布处理的信息进行管理，hadoop就是这样的一套解决方案。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>1、Hadoop是Apache旗下的一套开源适合大数据的分布式存储和计算平台平台</p>
<p>2、Hadoop提供的功能：利用服务器集群，根据户自定义业逻辑对海量数进行分布式处理</p>
<p>hadoop的概念：</p>
<p>　　狭义上： 就是apache的一个顶级项目：apahce hadoop</p>
<p>　　广义上: 就是指以hadoop为核心的整个大数据处理体系</p>
<h2 id="Hadoop的起源"><a href="#Hadoop的起源" class="headerlink" title="Hadoop的起源"></a>Hadoop的起源</h2><p>HADOOP最早起源于Nutch。Nutch的设计目标是构建一个大型的全网搜索引擎，为Apache Lucene项目的一部分，包括网页抓取、索引、查询等功能，但随着抓取网页数量的增加，遇到了严重的可扩展性问题——如何解决数十亿网页的存储和索引问题。<br>这个问题的解决方案源于Google的三大论文 ：GFS ，BigTable和MapReduce。受此启发的Doug Cutting（Hadoop之父）等人用业余时间实现了DFS和MapReduce机制。2006年2月从Nutch被分离出来，成为一套完整独立的软件，起名为Hadoop。</p>
<p>Hadoop的成长过程经历了：Lucene–&gt;Nutch—&gt;Hadoop</p>
<p>三篇论文的核心思想逐步演变，最终：</p>
<p>GFS—-&gt;HDFS<br>Google MapReduce—-&gt;Hadoop MapReduce<br>BigTable—-&gt;HBase</p>
<h2 id="Hadoop版本与架构核心"><a href="#Hadoop版本与架构核心" class="headerlink" title="Hadoop版本与架构核心"></a>Hadoop版本与架构核心</h2><p>Apache开源社区版本，现已到3.x </p>
<p>Hadoop1.0版本两个核心：HDFS+MapReduce</p>
<p>Hadoop2.0版本，引入了Yarn。核心：HDFS+Yarn+Mapreduce</p>
<p>​    Yarn是资源调度框架。能够细粒度的管理和调度任务。此外，还能够支持其他的计算框架，比如spark等。</p>
<p><img src="/2019/08/24/Hadoop开篇/1775767-20190824015110535-1305780494-20190824134434478.png" alt="img"></p>
<p>Hadoop3.0版本，未引入新核心，在原核心上，升级了很多东西。具体参见官网</p>
<h4 id="Hadoop的核心组件："><a href="#Hadoop的核心组件：" class="headerlink" title="Hadoop的核心组件："></a>Hadoop的核心组件：</h4><p>　　1）<strong>Hadoop Common</strong>：支持其他Hadoop模块的常用工具。</p>
<p>　　2)  <strong>Hadoop分布式文件系统（HDFS™）</strong>：一种分布式文件系统，可提供对应用程序数据的高吞吐量访问。</p>
<p>　　3)  <strong>Hadoop YARN</strong>：作业调度和集群资源管理的框架。</p>
<p>　　<strong>4)  Hadoop MapReduce</strong>：一种用于并行处理大型数据集的基于YARN的系统。</p>
<p>　　大数据的处理主要就是<strong>存储</strong>和<strong>计算</strong>。</p>
<p>如果说安装hadoop集群，其实就是安装了两个东西： 一个操作系统YARN 和 一个文件系统HDFS。其实MapReduce就是运行在YARN之上的应用。</p>
<p>操作系统 　　文件系统 　　应用程序<br>win7 　　　　NTFS　　　  QQ，WeChat<br>YARN 　　　 HDFS 　　    MapReduce</p>
<h2 id="Hadoop理念"><a href="#Hadoop理念" class="headerlink" title="Hadoop理念"></a>Hadoop理念</h2><p>Hadoop可运行于一般的商用服务器上，具有高容错、高可靠性、高扩展性等特点</p>
<p>特别适合写一次，读多次的场景</p>
<p> 适合场景</p>
<ul>
<li>大规模数据</li>
<li>流式数据（写一次，读多次）</li>
<li>商用硬件（一般硬件）</li>
</ul>
<p>不适合场景</p>
<ul>
<li>低延时的数据访问</li>
<li>大量的小文件</li>
<li>频繁修改文件</li>
</ul>
<h2 id="PS"><a href="#PS" class="headerlink" title="PS"></a>PS</h2><p>Hadoop起源的三个google论文   中文版</p>
<p><a href="http://blog.bizcloudsoft.com/wp-content/uploads/Google-File-System%E4%B8%AD%E6%96%87%E7%89%88_1.0.pdf" target="_blank" rel="noopener">GFS</a>  Google的分布式文件系统Google File System<br><a href="http://blog.bizcloudsoft.com/wp-content/uploads/Google-Bigtable%E4%B8%AD%E6%96%87%E7%89%88_1.0.pdf" target="_blank" rel="noopener">BigTable</a>  一个大型的分布式数据库<br><a href="http://blog.bizcloudsoft.com/wp-content/uploads/Google-MapReduce%E4%B8%AD%E6%96%87%E7%89%88_1.0.pdf" target="_blank" rel="noopener">MapReduce</a> Google的MapReduce开源分布式并行计算框架</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2016-2019 ID喵
            </div>
            <div class="footer-right">
                
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>