<!DOCTYPE html>
<html lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no">
<meta name="author" content="ID喵">


    
    


<meta property="og:type" content="website">
<meta property="og:title" content="ID喵">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="ID喵">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ID喵">

<link rel="apple-touch-icon" href="/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="ID喵" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">


    <style> .article { opacity: 0;} </style>


<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>ID喵</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: true,
        isPost: false,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: 
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head></html>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/langya.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">ID喵</a></h1>
        </hgroup>

        
        <p class="header-subtitle">喵了个喵，我又遇到瓶颈了...</p>
        

        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/archives/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="/xiaoran737@163.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="https://github.com/ValjeanShaw" title="GitHub"></a>
                            
                                <a class="fa 博客园" href="https://www.cnblogs.com/valjeanshaw/" title="博客园"></a>
                            
                                <a class="fa 掘金" href="https://juejin.im/user/5d5bd7106fb9a06b0c08695f" title="掘金"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/concurrent/">concurrent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分布式/">分布式</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">ID喵</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/langya.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">ID喵</a></h1>
            </hgroup>
            
            <p class="header-subtitle">喵了个喵，我又遇到瓶颈了...</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/archives/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="/xiaoran737@163.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="https://github.com/ValjeanShaw" title="GitHub"></a>
                            
                                <a class="fa 博客园" target="_blank" href="https://www.cnblogs.com/valjeanshaw/" title="博客园"></a>
                            
                                <a class="fa 掘金" target="_blank" href="https://juejin.im/user/5d5bd7106fb9a06b0c08695f" title="掘金"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap">
  
    <article id="post-分布式系列-二-一致性协议 2PC和3PC" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/19/分布式系列-二-一致性协议 2PC和3PC/" class="article-date">
      <time datetime="2019-09-19T12:00:40.000Z" itemprop="datePublished">2019-09-19</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/19/分布式系列-二-一致性协议 2PC和3PC/">分布式系列 (二) 一致性协议 2PC和3PC</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<p>为解决分布式问题，涌现了一大批经典的一致性协议和算法。最著名的就是2PC，3PC，和Paxos算法。</p>
<h2 id="2PC和3PC"><a href="#2PC和3PC" class="headerlink" title="2PC和3PC"></a>2PC和3PC</h2><p>当一个事务操作需要跨越多个分布式节点的时候，为保持事务处理的ACID特性，需要引入一个<strong>协调者</strong>来统一调度所有分布式节点的执行逻辑，这些被调度的分布式节点被称为<strong>参与者</strong>。协调者负责调度参与者的行为，并最终决定这些参与者是否要把事务真正提交。由此衍生出2pc和3pc</p>
<h3 id="2PC-二阶段提交协议"><a href="#2PC-二阶段提交协议" class="headerlink" title="2PC 二阶段提交协议"></a>2PC 二阶段提交协议</h3><p>二阶段提交协议是把事务的提交过程分成两个阶段处理。</p>
<ul>
<li>阶段一：提交事务请求</li>
<li>阶段二：执行事务提交</li>
</ul>
<p><strong>二阶段提交的核心思想就是对每一个事务都采用先尝试后提交的处理方式，因此也可以将二阶段提交看作是一个强一致性算法。</strong></p>
<p>阶段1中，协调者发起一个提议，分别问询各参与者是否接受</p>
<p>![image-20190922233819996](分布式系列-二-一致性协议 2PC和3PC/image-20190922233819996.png)</p>
<p>在阶段2中，协调者根据参与者的反馈，提交或中止事务，如果参与者全部同意则提交，只要有一个参与者不同意就中止。</p>
<p>![image-20190922233839319](分布式系列-二-一致性协议 2PC和3PC/image-20190922233839319.png)</p>
<p>二阶段提交有几个优点：原理简单，容易实现。</p>
<p>二阶段提交有几个<strong>缺点：</strong></p>
<ul>
<li><strong>同步阻塞问题</strong>。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。</li>
<li><strong>单点故障</strong>。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）</li>
<li><strong>数据不一致</strong>。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。</li>
<li><strong>二阶段无法解决的问题</strong>：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。</li>
</ul>
<h3 id="3PC-三阶段提交协议"><a href="#3PC-三阶段提交协议" class="headerlink" title="3PC 三阶段提交协议"></a>3PC 三阶段提交协议</h3><p>三阶段提交（3PC），是二阶段提交（2PC）的改进。有两个改动点。</p>
<ul>
<li>引入超时机制。同时在协调者和参与者中都引入超时机制。</li>
<li>在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。</li>
</ul>
<p>三阶段提交有以下3个阶段：</p>
<ul>
<li><p>阶段一：CanCommit。</p>
<p>事务询问，参与者响应。协调者询问是否可以进行事务操作，参与者反馈</p>
</li>
<li><p>阶段二：PreCommit。</p>
<p>两种可能。</p>
<p>1.协调者获得的所有反馈都是Yes，执行事务的预执行。</p>
<ul>
<li><strong>发送预提交请求</strong> 协调者向参与者发送PreCommit请求，并进入Prepared阶段。</li>
<li><strong>事务预提交</strong> 参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。</li>
<li><strong>响应反馈</strong> 如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。</li>
</ul>
<p>2.任一个参与者向协调者发送了No，或等待超时。执行事务的中断。</p>
<ul>
<li>发送中断请求 协调者向所有参与者发送abort请求。</li>
<li>中断事务 参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。</li>
</ul>
</li>
<li><p>阶段三：doCommit</p>
<p>该阶段进行真正的事务提交，也分两种情况。</p>
<p><strong>1.执行提交</strong></p>
<ul>
<li><strong>发送提交请求</strong> 协调者收到所有Ack响应，将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。</li>
<li><strong>事务提交</strong> 参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。</li>
<li><strong>响应反馈</strong> 事务提交完之后，向协调者发送Ack响应。</li>
<li><strong>完成事务</strong> 协调者接收到所有参与者的Ack响应之后，完成事务。</li>
</ul>
<p><strong>2.中断事务</strong></p>
<p>协调者没有<strong>完全接收</strong>到所有的Ack响应，执行中断事务。</p>
<ul>
<li>协调者向所有参与者发送abort中断请求</li>
<li>事务回滚。参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。</li>
<li>反馈结果。参与者完成事务回滚之后，向协调者发送Ack消息</li>
<li>中断事务。协调者接收到参与者反馈的Ack消息之后，执行事务的中断。</li>
</ul>
</li>
</ul>
<p>![image-20190923233335948](分布式系列-二-一致性协议 2PC和3PC/image-20190923233335948.png)</p>
<h2 id="2PC和3PC的区别"><a href="#2PC和3PC的区别" class="headerlink" title="2PC和3PC的区别"></a>2PC和3PC的区别</h2><p>相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，参与者会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。</p>
<p>在2PC中一个参与者的状态只有它自己和协调者知晓，假如协调者提议后自身宕机，在协调者备份启用前一个参与者又宕机，其他参与者就会进入既不能回滚、又不能强制commit的阻塞状态，直到参与者宕机恢复。</p>
<p>参与者如果在不同阶段宕机，3PC如何应对：</p>
<ul>
<li><strong>阶段1</strong>: 协调者或协调者备份未收到宕机参与者的vote，直接中止事务；宕机的参与者恢复后，读取logging发现未发出赞成vote，自行中止该次事务</li>
<li><strong>阶段2</strong>: 协调者未收到宕机参与者的precommit ACK，但因为之前已经收到了宕机参与者的赞成反馈(不然也不会进入到阶段2)，协调者进行commit；协调者备份可以通过问询其他参与者获得这些信息，过程同理；宕机的参与者恢复后发现收到precommit或已经发出赞成vote，则自行commit该次事务</li>
<li><strong>阶段3</strong>: 即便协调者或协调者备份未收到宕机参与者t的commit ACK，也结束该次事务；宕机的参与者恢复后发现收到commit或者precommit，也将自行commit该次事务</li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/分布式/">分布式</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/分布式/">分布式</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-分布式系列-一-分布式架构概念" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/09/分布式系列-一-分布式架构概念/" class="article-date">
      <time datetime="2019-09-09T15:13:42.000Z" itemprop="datePublished">2019-09-09</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/09/分布式系列-一-分布式架构概念/">分布式系列 (一) 分布式架构概念</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="集中式系统架构与分布式系统架构"><a href="#集中式系统架构与分布式系统架构" class="headerlink" title="集中式系统架构与分布式系统架构"></a>集中式系统架构与分布式系统架构</h2><p>集中式系统：由卓越性能的大型主机单机组成的计算机系统，称为集中式系统。</p>
<p>特点。单机运算能力强劲，部署结构简单。但是，拥有单点故障，且单机价格昂贵。</p>
<p>分布式系统：一个硬件或者软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。</p>
<p>特点：</p>
<ol>
<li>分布性。多台计算机在空间中任意分布，且分布情况随时变动。</li>
<li>对等性。分布式系统中计算机硬件没有主从之分。</li>
<li>并发性。并发的操作共享资源（分布式系统最大挑战之一）。</li>
<li>缺乏全局时钟。分布式系统中时间的先后，缺乏全局时钟序列控制。</li>
<li>故障总是发生。组成分布式系统的计算机，随时都有可能发生任何形式故障</li>
</ol>
<h2 id="分布式系统架构中的挑战"><a href="#分布式系统架构中的挑战" class="headerlink" title="分布式系统架构中的挑战"></a>分布式系统架构中的挑战</h2><h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>定义：一系列对系统中数据进行访问与更新的操作所组成的一个程序执行单元。狭义上的事务特指数据库事务。</p>
<p>4大特性：ACID</p>
<p>原子性 Atomicity    一致性 Consistency    隔离性Isolation    持久性Durability</p>
<p>原子性指事务必须是一个原子的操作序列单元，只允许出现全部成功执行和全部不执行两个状态。</p>
<p>一致性指事务执行的结果必须是使系统从一个一致性状态变为另一个一致性状态。比如数据库事务中，出现故障事务失败，但是数据写入了部分，此为不一致状态。</p>
<p>隔离性指一个事务的执行不能被其它事务干扰。</p>
<p>持久性指事务一旦提交，对系统的变更是永久性的。比如数据库事务操作完毕，数据持久到磁盘。</p>
<h3 id="分布式事务和数据一致性"><a href="#分布式事务和数据一致性" class="headerlink" title="分布式事务和数据一致性"></a>分布式事务和数据一致性</h3><p>一个分布式事务可看作由多个分布式的操作序列组成，由于在分布式事务中，各个子事务的执行是分散的，因此要实现一种能够保证ACID特性的分布式事务处理系统格外复杂。</p>
<p>举个典型的分布式事务场景：一个跨银行的转账操作涉及调用两个异地的银行服务，其中一个是本地银行提供的取款服务，另一个则是目标银行提供的存款服务，这两个服务本身是无状态并且相互独立的，共同构成了一个完整的分布式事物。如果从本地银行取款成功，但是因为某种原因存款服务失败了，那么就必须回滚到取款之前的状态，否则用户可能会发现自己的钱不翼而飞了。</p>
<h4 id="CAP定理"><a href="#CAP定理" class="headerlink" title="CAP定理"></a>CAP定理</h4><p>一个经典的分布式系统理论。CAP理论：<strong>一个分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容错性（P：Partition tolerance）这三个基本需求，最多只能同时满足其中两项。</strong></p>
<p>C 一致性：一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致的状态</p>
<p>A 可用性：系统提供的服务必须一致处于可用的状态，对于用户的每一个操作请求总是能够在<strong>有限时间</strong>内<strong>返回结果</strong></p>
<p>P 分区容错性：分布式系统在遇到任何网络分区故障的时候，仍然需要能够对外满足一致性和可用性的服务，除非网络环境都发生故障</p>
<table>
<thead>
<tr>
<th align="left">选择</th>
<th><strong>说    明</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left">CA</td>
<td>放弃分区容错性，加强一致性和可用性，其实就是传统的单机数据库的选择</td>
</tr>
<tr>
<td align="left">AP</td>
<td>放弃一致性（追求最终一致性），追求分区容错性和可用性，这是很多分布式系统设计时的选择，例如很多NoSQL系统就是如此</td>
</tr>
<tr>
<td align="left">CP</td>
<td>放弃可用性，追求一致性和分区容错性，基本不会选择，网络问题会直接让整个系统不可用</td>
</tr>
</tbody></table>
<p>需要明确的一点是：对于一个分布式系统来说，分区容错性可以说是一个最基本的需求。因为既然是一个分布式系统，那么分布式系统中的组件必然需要部署在不同节点，因此会出现子网络，因此分区容错性成为了一个分布式系统必然要面对和解决的问题。因此系统设计师往往在一致性和可用性之间做平衡取舍。由此引发Base理论。</p>
<h4 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h4><p>BASE是对CAP中一致性和可用性权衡的结果，核心思想是即使无法做到强一致性，但是每个应用都可以根据自身业务特点，采用适当的方式使系统达到最终一致性。</p>
<p>BASE理论三要素：</p>
<ol>
<li>基本可用    Basically Available</li>
<li>软状态    Soft state</li>
<li>最终一致性    Eventually consistent</li>
</ol>
<p>三要素详细解释：</p>
<h5 id="基本可用"><a href="#基本可用" class="headerlink" title="基本可用"></a>基本可用</h5><p>分布式系统出现不可预知故障的时候，允许损失部分可用性</p>
<p>例：集群中部分机器宕机，导致剩余机器压力过大，查询效率从0.5s降到了2s</p>
<h5 id="弱状态"><a href="#弱状态" class="headerlink" title="弱状态"></a>弱状态</h5><p>允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。</p>
<h5 id="最终一致性"><a href="#最终一致性" class="headerlink" title="最终一致性"></a>最终一致性</h5><p>最终一致性强调在系统的所有数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。</p>
<p>总的来说。BASE 理论面向的是大型高可用可扩展的分布式系统，和传统事务的 ACID 是<strong>相反的</strong>，它完全不同于 ACID 的强一致性模型，而是<strong>通过牺牲强一致性</strong>来获得可用性，并允许数据在一段时间是不一致的。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/分布式/">分布式</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/分布式/">分布式</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop系列（五）Hadoop三大核心之HDFS-读写流程" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/" class="article-date">
      <time datetime="2019-09-08T07:31:34.000Z" itemprop="datePublished">2019-09-08</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/">Hadoop系列（五）Hadoop三大核心之HDFS 读写流程</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<p>首先，再回顾一下HDFS的架构图</p>
<p><img src="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/image-20190908154045344.png" alt="image-20190908154045344"></p>
<h2 id="HDFS写数据流程"><a href="#HDFS写数据流程" class="headerlink" title="HDFS写数据流程"></a>HDFS写数据流程</h2><p><img src="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/image-20190908154424852.png" alt="image-20190908154424852"></p>
<ol>
<li>客户端发送请求，调用DistributedFileSystem API的create方法去请求namenode，并告诉namenode上传文件的文件名、文件大小、文件拥有者。</li>
<li>namenode根据以上信息算出文件需要切成多少块block，以及block要存放在哪个datanode上，并将这些信息返回给客户端。</li>
<li>客户端调用FSDataInputStream API的write方法首先将其中一个block写在datanode上。</li>
<li>每一个block多个副本（默认3个），由已经上传了block的datanode产生新的线程，按照放置副本规则往其它datanode写副本。（并不是由客户端分别往3个datanode上写3份，这样的优势就是快。）</li>
<li>写完后返回给客户端一个信息，然后客户端在将信息反馈给namenode。更新元数据。</li>
</ol>
<h2 id="HDFS读流程"><a href="#HDFS读流程" class="headerlink" title="HDFS读流程"></a>HDFS读流程</h2><p><img src="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/image-20190908155152510.png" alt="image-20190908155152510"></p>
<ol>
<li>客户端通过调用FileSystem对象中的open()方法来读取需要的数据</li>
<li>DistributedFileSystem会通过RPC协议调用NameNode来查找文件块所在的位置</li>
</ol>
<blockquote>
<p><strong>NameNode只会返回所调用文件中开始的几个块而不是全部返回。对于每个返回的块，都包含块所在的DataNode的地址。随后，这些返回的DataNode会按照Hadoop集群的拓扑结构得出客户端的距离，然后再进行排序。如果客户端本身就是DataNode，那么它就从本地读取文件。</strong>其次，DistributedFileSystem会向客户端返回一个支持定位的输入流对象FSDataInputStream，用于给客户端读取数据。FSDataInputStream包含一个DFSInputStream对象，这个对象来管理DataNode和NameNode之间的IO</p>
</blockquote>
<ol start="3">
<li><p>当以上步骤完成时，客户端便会在这个输入流上调用read()方法</p>
</li>
<li><p>DFSInputStream对象中包含文件开始部分数据块所在的DataNode地址，首先它会连接文件第一个块最近的DataNode，随后在数据流中重复调用read方法，直到这个块读完为止。</p>
</li>
<li><p>当第一个块读取完毕时，DFSInputStream会关闭连接，并查找存储下一个数据块距离客户端最近的DataNode，以上这些步骤对客户端来说都是透明的。</p>
</li>
<li><p>当完成所有块的读取时，客户端则会在DFSInputStream中调用close()方法。</p>
</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-序列化" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/05/序列化/" class="article-date">
      <time datetime="2019-09-05T15:55:22.000Z" itemprop="datePublished">2019-09-05</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/05/序列化/">序列化</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="一、序列化和反序列化的定义和场景"><a href="#一、序列化和反序列化的定义和场景" class="headerlink" title="一、序列化和反序列化的定义和场景"></a>一、序列化和反序列化的定义和场景</h2><p>序列化：将对象写入到IO流中</p>
<p>反序列化：从IO流中恢复对象</p>
<p>序列化机制将实现序列化的Java对象转化为字节数组序列。可以使对象可以脱离程序而独立运行</p>
<p>场景和要求：保存到磁盘；在网络中传输。要保存到磁盘和在远程传输的java对象要求都必须是可序列化的。</p>
<p><img src="/2019/09/05/序列化/image-20190907150807138.png" alt="image-20190907150807138"></p>
<h2 id="二、序列化和反序列化的java实现"><a href="#二、序列化和反序列化的java实现" class="headerlink" title="二、序列化和反序列化的java实现"></a>二、序列化和反序列化的java实现</h2><h3 id="Serializable接口"><a href="#Serializable接口" class="headerlink" title="Serializable接口"></a>Serializable接口</h3><p>一个标记接口，不用实现任何方法。一旦实现了此接口，该类的对象就是可序列化的。</p>
<h4 id="序列化步骤"><a href="#序列化步骤" class="headerlink" title="序列化步骤"></a>序列化步骤</h4><p>1 创建ObjectOutputStream输出流；2 调用ObjectOutputStream对象的writeObject输出可序列化对象。</p>
<p>若对象不是序列化对象，序列化是将抛出 NotSerializableException 异常</p>
<h4 id="反序列化步骤"><a href="#反序列化步骤" class="headerlink" title="反序列化步骤"></a>反序列化步骤</h4><p>1 创建ObjectInputStream输入流；2 调用ObjectInputStream对象的readObject()得到可序列化对象</p>
<p>demo:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">People</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> String city;</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCity</span><span class="params">(String city)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.city = city;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        People people = <span class="keyword">new</span> People();</span><br><span class="line">        people.setCity(<span class="string">"成都"</span>);</span><br><span class="line">        people.setName(<span class="string">"假老练"</span>);</span><br><span class="line">        People people1 = <span class="keyword">new</span> People();</span><br><span class="line">        people1.setCity(<span class="string">"北京"</span>);</span><br><span class="line">        people1.setName(<span class="string">"风车车"</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            FileOutputStream fileOutputStream = <span class="keyword">new</span> FileOutputStream(<span class="string">"object.txt"</span>);</span><br><span class="line">            ObjectOutputStream os = <span class="keyword">new</span> ObjectOutputStream(fileOutputStream);</span><br><span class="line">            os.writeObject(people);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            FileInputStream fileInputStream = <span class="keyword">new</span> FileInputStream(<span class="string">"object.txt"</span>);</span><br><span class="line">            ObjectInputStream os = <span class="keyword">new</span> ObjectInputStream(fileInputStream);</span><br><span class="line">            People peopleResult = (People) os.readObject();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>如果需要序列化的类的属性含有非基本数据类型和String类型，即引用类型，那么该引用类型也比如可序列化</strong>。否则依然会抛出 NotSerializableException 异常</p>
<h4 id="serialVersionUID的作用"><a href="#serialVersionUID的作用" class="headerlink" title="serialVersionUID的作用"></a>serialVersionUID的作用</h4><p>Java 的序列化，通过在运行时判断类的serialVersionUID来验证版本一致性。</p>
<p>在进行反序列化时，JVM 会把传来的字节流中的serialVersionUID与本地相应实体（类）的serialVersionUID进行比较，如果相同就认为是一致的，可以进行反序列化，否则就会出现序列化版本不一致的异常。实测如果id一致，属性发生较小变化，对象也会创建出来，并将属性按属性名对号入座。</p>
<p> 当实现序列化的时候，建议显式定义serialVersionUID，若不显式定义 serialVersionUID 的值，Java 会根据类细节自动生成 serialVersionUID 的值。可能造成以下两个问题。1.如果对类的源代码作了修改，再重新编译，新生成的类文件的serialVersionUID的取值有可能也会发生变化。2.类的serialVersionUID的默认值完全依赖于Java编译器的实现，对于同一个类，用不同的Java编译器编译，也有可能会导致不同的serialVersionUID，即不同机器或不同版本jdk反序列化可能失败。</p>
<p>##总计 </p>
<ol>
<li>序列化是将对象写入到IO字节流，反序列化是从IO字节流中恢复对象</li>
<li>序列化的两个主要作用是用来存储和网络传输</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/">java</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-进程，线程与多核，多cpu之间的关系" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/02/进程，线程与多核，多cpu之间的关系/" class="article-date">
      <time datetime="2019-09-02T02:55:41.000Z" itemprop="datePublished">2019-09-02</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/02/进程，线程与多核，多cpu之间的关系/">进程，线程与多核，多cpu之间的关系</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="cpu架构和工作原理"><a href="#cpu架构和工作原理" class="headerlink" title="cpu架构和工作原理"></a>cpu架构和工作原理</h2><p>计算机有5大基本组成部分，运算器，控制器，存储器，输入和输出。运算器和控制器封装到一起，加上寄存器组和cpu内部总线构成中央处理器（CPU）。cpu的根本任务，就是执行指令，对计算机来说，都是0，1组成的序列，cpu从逻辑上可以划分为3个模块：控制单元、运算单元和存储单元。这三个部分由cpu总线连接起来。</p>
<p><img src="/2019/09/02/进程，线程与多核，多cpu之间的关系/image-20190902202929616.png" alt="image-20190902202929616"></p>
<p>CPU的运行原理就是：控制单元在时序脉冲的作用下，将指令计数器里所指向的指令地址(这个地址是在内存里的)送到地址总线上去，然后CPU将这个地址里的指令读到指令寄存器进行译码。对于执行指令过程中所需要用到的数据，会将数据地址也送到地址总线，然后CPU把数据读到CPU的内部存储单元(就是内部寄存器)暂存起来，最后命令运算单元对数据进行处理加工。周而复始，一直这样执行下去。</p>
<h2 id="多核cpu和多cpu"><a href="#多核cpu和多cpu" class="headerlink" title="多核cpu和多cpu"></a>多核cpu和多cpu</h2><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>多个物理CPU，CPU通过总线进行通信，效率比较低。</p>
<p><img src="/2019/09/02/进程，线程与多核，多cpu之间的关系/image-20190904121329148.png" alt="image-20190904121329148"></p>
<p>多核CPU，不同的核通过L2 cache进行通信，存储和外设通过总线与CPU通信</p>
<p><img src="/2019/09/02/进程，线程与多核，多cpu之间的关系/image-20190904121349591.png" alt="image-20190904121349591"></p>
<h3 id="cpu的缓存"><a href="#cpu的缓存" class="headerlink" title="cpu的缓存"></a>cpu的缓存</h3><p>CPU缓存是位于CPU与内存之间的临时数据交换器，它的容量比内存小的多但是交换速度却比内存要快得多。CPU缓存一般直接跟CPU芯片集成或位于主板总线互连的独立芯片上。</p>
<p><img src="/2019/09/02/进程，线程与多核，多cpu之间的关系/image-20190905092214302.png" alt="image-20190905092214302"></p>
<p>随着多核CPU的发展，CPU缓存通常分成了三个级别：<code>L1</code>，<code>L2</code>，<code>L3</code>。级别越小越接近CPU，所以速度也更快，同时也代表着容量越小。L1 是最接近CPU的, 它容量最小（例如：<code>32K</code>），速度最快，每个核上都有一个 L1 缓存，L1 缓存每个核上其实有两个 L1 缓存, 一个用于存数据的 L1d Cache（Data Cache），一个用于存指令的 L1i Cache（Instruction Cache）。L2 缓存 更大一些（例如：<code>256K</code>），速度要慢一些, 一般情况下每个核上都有一个独立的L2 缓存; L3 缓存是三级缓存中最大的一级（例如3MB），同时也是最慢的一级, 在同一个CPU插槽之间的核共享一个 L3 缓存。</p>
<p>读取数据过程。就像数据库缓存一样，首先在最快的缓存中找数据，如果缓存没有命中(Cache miss) 则往下一级找, 直到三级缓存都找不到时，向内存要数据。一次次地未命中，代表取数据消耗的时间越长。</p>
<p>计算过程。程序以及数据被加载到主内存；指令和数据被加载到CPU的高速缓；CPU执行指令，把结果写到高速缓存；高速缓存中的数据写回主内存</p>
<h2 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h2><p>进程是程序的一次执行，一个程序有至少一个进程，是<code>资源分配的最小单位</code>，资源分配包括cpu、内存、磁盘IO等。线程是<code>程序执行的最小单位</code>,一个进程有至少一个线程。</p>
<h2 id="进程和线程在多核cpu，多cpu中的运行关系"><a href="#进程和线程在多核cpu，多cpu中的运行关系" class="headerlink" title="进程和线程在多核cpu，多cpu中的运行关系"></a>进程和线程在多核cpu，多cpu中的运行关系</h2><p>多cpu的运行，是针对进程的运行状态来说的；多核cpu的运行，是针对线程的运行状态来说的。</p>
<p>操作系统会拆分CPU为一段段时间的运行片，轮流分配给不同的程序。对于多cpu，多个进程可以并行在多个cpu中计算，当然也会存在进程切换；对于单cpu，多个进程在这个单cpu中是并发运行，根据时间片读取上下文+执行程序+保存上下文。同一个进程同一时间段只能在一个cpu中运行，如果进程数小于cpu数，那么未使用的cpu将会空闲。</p>
<p>对于多核cpu，进程中的多线程并行执行，执行过程中存在线程切换，线程切换开销较小。对于单核cpu，多线程在单cpu中并发执行，根据时间片切换线程。同一个线程同一时间段只能在一个cpu内核中运行，如果线程数小于cpu内核数，那么将有多余的内核空闲。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>1 单CPU中进程只能是并发，多CPU计算机中进程可以并行。</p>
<p>2单CPU单核中线程只能并发，单CPU多核中线程可以并行。</p>
<p>3 无论是并发还是并行，使用者来看，看到的是多进程，多线程。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/concurrent/">concurrent</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop系列（六）Hadoop三大核心之MapReduce-基础" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/01/Hadoop系列（六）Hadoop三大核心之MapReduce-基础/" class="article-date">
      <time datetime="2019-09-01T08:51:48.000Z" itemprop="datePublished">2019-09-01</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/01/Hadoop系列（六）Hadoop三大核心之MapReduce-基础/">Hadoop系列（六）Hadoop三大核心之MapReduce 基础</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="MapReduce背景"><a href="#MapReduce背景" class="headerlink" title="MapReduce背景"></a>MapReduce背景</h2><p>设想一个海量数据场景下的数据计算需求：</p>
<ul>
<li><p>单机版：磁盘受限，内存受限，计算能力受限</p>
</li>
<li><p>分布式版：</p>
<p>1  数据存储的问题，hadoop 提供了 hdfs 解决了数据存储这个问题</p>
<p>2 运算逻辑至少要分为两个阶段，先并发计算（map），然后汇总（reduce）结果</p>
<p>3 这两个阶段的计算如何启动？如何协调？</p>
<p>4 运算程序到底怎么执行？数据找程序还是程序找数据？</p>
<p>5如何分配两个阶段的多个运算任务？</p>
<p>6如何管理任务的执行过程中间状态，如何容错？</p>
<p>7如何监控？</p>
<p>8出错如何处理？抛异常？重试？</p>
</li>
</ul>
<p>　　可见在程序由单机版扩成分布式版时，会引入大量的复杂工作。为了提高开发效率，可以将分布式程序中的公共功能封装成框架，让开发人员可以将精力集中于业务逻辑。Hadoop 当中的 MapReduce 就是这样的一个分布式程序运算框架。</p>
<h2 id="MapReduce是什么"><a href="#MapReduce是什么" class="headerlink" title="MapReduce是什么"></a>MapReduce是什么</h2><p><strong>MapReduce是一个分布式运算程序的编程框架，是用户开发“基于 Hadoop 的数据分析应用” 的核心框架。其核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上。</strong></p>
<p>MapReduce可以分成Map和Reduce两部分理解。</p>
<ol>
<li><p>Map：映射过程，把一组数据按照某种Map函数映射成新的数据。</p>
</li>
<li><p>Reduce：归约过程，把若干组映射结果进行汇总并输出。</p>
</li>
</ol>
<p>基于MapReduce写出来的应用程序能够运行在由上千个商用机器组成的大型集群上，并以一种可靠容错的方式并行处理上T级别的数据集。一个Map/Reduce <em>作业（job）</em> 通常会把输入的数据集切分为若干独立的数据块，由 <em>map任务（task）</em>以完全并行的方式处理它们。框架会对map的输出先进行排序， 然后把结果输入给<em>reduce任务</em>。通常作业的输入和输出都会被存储在文件系统中。 整个框架负责任务的调度和监控，以及重新执行已经失败的任务。</p>
<h2 id="MapReduce的结构"><a href="#MapReduce的结构" class="headerlink" title="MapReduce的结构"></a>MapReduce的结构</h2>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop系列（四）Hadoop三大核心之HDFS-Java-API" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/01/Hadoop系列（四）Hadoop三大核心之HDFS-Java-API/" class="article-date">
      <time datetime="2019-09-01T08:51:48.000Z" itemprop="datePublished">2019-09-01</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/01/Hadoop系列（四）Hadoop三大核心之HDFS-Java-API/">Hadoop系列（四）Hadoop三大核心之HDFS Java API</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<p>HDFS 设计的主要目的是对海量数据进行存储，也就是说在其上能够存储很大量的文件。</p>
<p>HDFS 将这些文件分割之后，存储在不同的 DataNode 上，HDFS 提供了通过Java API 对 HDFS 里面的文件进行操作的功能，数据块在 DataNode 上的存放位置，对于开发者来说是透明的。</p>
<p>使用 Java API 可以完成对 HDFS 的各种操作，如新建文件、删除文件、读取文件内容等。下面将介绍 HDFS 常用的 Java API 及其编程实例。</p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><ul>
<li>Configuration   封装了客户端或者服务器的配置</li>
<li>FileSystem  文件系统对象，用该对象的方法来对文件进行操作</li>
<li>FileStatus   用于向客户端展示系统中文件和目录的元数据</li>
<li>FSDatalnputStream   HDFS 中的输入流，用于读取 Hadoop 文件</li>
<li>FSDataOutputStream   HDFS 中的输出流，用于写 Hadoop 文件</li>
<li>Path   用于表示 Hadoop 文件系统中的文件或者目录的路径</li>
</ul>
<h2 id="具体操作"><a href="#具体操作" class="headerlink" title="具体操作"></a>具体操作</h2><ol>
<li>导入maven依赖包</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>初始化配置</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Configuration conf;</span><br><span class="line">FileSystem fileSystem;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HdfsAPI</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    conf.set(<span class="string">"dfs.replication"</span>, <span class="string">"2"</span>);</span><br><span class="line">    conf.set(<span class="string">"dfs.blocksize"</span>, <span class="string">"128m"</span>);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        fileSystem = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://$&#123;NameNode&#125;:9000"</span>), conf, <span class="string">"hadoop"</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>get文件   get</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testGet</span><span class="params">()</span> <span class="keyword">throws</span> IllegalArgumentException, IOException </span>&#123;</span><br><span class="line">    fileSystem.copyToLocalFile(<span class="keyword">new</span> Path(<span class="string">"/output/part.txt"</span>), <span class="keyword">new</span> Path(<span class="string">"~/Downloads"</span>));</span><br><span class="line">    fileSystem.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>获取文件信息   ls</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testLs</span><span class="params">()</span> <span class="keyword">throws</span> IllegalArgumentException, IOException </span>&#123;</span><br><span class="line">    RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fileSystem.listFiles(<span class="keyword">new</span> Path(<span class="string">"/"</span>), <span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">while</span> (listFiles.hasNext()) &#123;</span><br><span class="line">        LocatedFileStatus status = listFiles.next();</span><br><span class="line">        System.out.println(<span class="string">"路径："</span> + status.getPath());</span><br><span class="line">        System.out.println(<span class="string">"块大小："</span> + status.getBlockSize());</span><br><span class="line">        System.out.println(<span class="string">"文件长度："</span> + status.getLen());</span><br><span class="line">        System.out.println(<span class="string">"副本数:"</span> + status.getReplication());</span><br><span class="line">        System.out.println(<span class="string">"块的位置信息："</span> + Arrays.toString(status.getBlockLocations()) + <span class="string">"\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    fileSystem.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>创建目录，多级目录    mkdir</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testMkdir</span><span class="params">()</span> <span class="keyword">throws</span> IllegalArgumentException, IOException </span>&#123;</span><br><span class="line">    fileSystem.mkdirs(<span class="keyword">new</span> Path(<span class="string">"/output/test/testmk"</span>));</span><br><span class="line">    fileSystem.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>删除文件，目录  rm</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testDeldir</span><span class="params">()</span> <span class="keyword">throws</span> IllegalArgumentException, IOException </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> delete = fileSystem.delete(<span class="keyword">new</span> Path(<span class="string">"/output/test/testmk"</span>), <span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">if</span> (delete) &#123;</span><br><span class="line">        System.out.println(<span class="string">"文件已经删除"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    fileSystem.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="7">
<li>读取hdfs文件内容</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testReadData</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    FSDataInputStream in = fileSystem.open(<span class="keyword">new</span> Path(<span class="string">"/test.txt"</span>));<span class="comment">//hdfs自带流打开文件</span></span><br><span class="line">    BufferedReader br = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(in, <span class="string">"utf-8"</span>));<span class="comment">//读入流并放在缓冲区</span></span><br><span class="line">    String line = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">while</span> ((line = br.readLine()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">        System.out.println(line);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    in.close();</span><br><span class="line">    br.close();</span><br><span class="line">    fileSystem.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="8">
<li>读取hdfs中文件中指定偏移的内容</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testRandomReadData</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    FSDataInputStream in = fileSystem.open(<span class="keyword">new</span> Path(<span class="string">"/test.txt"</span>));</span><br><span class="line">    in.seek(<span class="number">12</span>);<span class="comment">//定位到12位置开始读</span></span><br><span class="line">    <span class="keyword">byte</span>[] buf = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">16</span>];<span class="comment">//往后读取16个位</span></span><br><span class="line">    in.read(buf);<span class="comment">//ba流读到buf中</span></span><br><span class="line">    System.out.println(<span class="keyword">new</span> String(buf));</span><br><span class="line">    in.close();</span><br><span class="line">    fileSystem.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="9">
<li>数据写到hdfs中</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testWriteData</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    FSDataOutputStream out = fileSystem.create(<span class="keyword">new</span> Path(<span class="string">"/yy.jpg"</span>), <span class="keyword">false</span>);</span><br><span class="line">    FileInputStream in = <span class="keyword">new</span> FileInputStream(<span class="string">"~/Download/wechatpic_20190309221605.jpg"</span>);</span><br><span class="line">    <span class="keyword">byte</span>[] buf = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">    <span class="keyword">int</span> read = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> ((read = in.read(buf)) != -<span class="number">1</span>) &#123;</span><br><span class="line">        out.write(buf, <span class="number">0</span>, read);</span><br><span class="line">    &#125;</span><br><span class="line">    out.close();</span><br><span class="line">    fileSystem.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop系列（三）Hadoop三大核心之HDFS-shell常用命令" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/08/29/Hadoop系列（三）Hadoop三大核心之HDFS-shell常用命令/" class="article-date">
      <time datetime="2019-08-29T15:51:48.000Z" itemprop="datePublished">2019-08-29</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/08/29/Hadoop系列（三）Hadoop三大核心之HDFS-shell常用命令/">Hadoop系列（三）Hadoop三大核心之HDFS shell常用命令</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="HDFS常用命令"><a href="#HDFS常用命令" class="headerlink" title="HDFS常用命令"></a>HDFS常用命令</h2><h3 id="help-查看所有命令"><a href="#help-查看所有命令" class="headerlink" title="help 查看所有命令"></a>help 查看所有命令</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs help</code></p>
<h3 id="查看路径文件"><a href="#查看路径文件" class="headerlink" title="查看路径文件"></a>查看路径文件</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -ls /</code></p>
<h3 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -mkdir /test</code></p>
<h3 id="创建多级文件夹"><a href="#创建多级文件夹" class="headerlink" title="创建多级文件夹"></a>创建多级文件夹</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -mkdir -p /test/test1/test2</code></p>
<h3 id="查看指定目录下和子目录下所有文件"><a href="#查看指定目录下和子目录下所有文件" class="headerlink" title="查看指定目录下和子目录下所有文件"></a>查看指定目录下和子目录下所有文件</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -ls -R /test</code></p>
<h3 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -put part.txt /test</code></p>
<p>or</p>
<p><code>[172.23.7.9:hadoop]$ hadoop fs -copyFromLocal part.txt /test</code></p>
<h3 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -get /test/part.txt ~/test</code></p>
<p>or</p>
<p><code>[172.23.7.9:hadoop]$ hadoop fs -copyToLocal /test/part.txt ~/test</code></p>
<h3 id="合并下载"><a href="#合并下载" class="headerlink" title="合并下载"></a>合并下载</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -getmerge /test/part0.txt /test/part1.txt ./temp.txt</code></p>
<h3 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -cp /test/part.txt /output</code></p>
<h3 id="移动"><a href="#移动" class="headerlink" title="移动"></a>移动</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -mv /test/part.txt /output</code></p>
<h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -rm /test/part.txt</code></p>
<p>强制删除</p>
<p><code>[172.23.7.9:hadoop]$ hadoop fs -rm -r /test/part.txt</code></p>
<h3 id="查看文件内容"><a href="#查看文件内容" class="headerlink" title="查看文件内容"></a>查看文件内容</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -cat /test/part.txt</code></p>
<h3 id="显示文件大小"><a href="#显示文件大小" class="headerlink" title="显示文件大小"></a>显示文件大小</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -du -h /test/part.txt</code></p>
<h3 id="test"><a href="#test" class="headerlink" title="test"></a>test</h3><p><code>[172.23.7.9:hadoop]$ hadoop fs -test -[ezd] /test/part.txt</code></p>
<p>选项：<br>-e 检查文件是否存在。如果存在则返回0。<br>-z 检查文件是否是0字节。如果是则返回0。<br>-d 如果路径是个目录，则返回1，否则返回0。</p>
<h2 id="web界面"><a href="#web界面" class="headerlink" title="web界面"></a>web界面</h2><p><code>http://xx.xx.xx.xx:9870/explorer.html#/</code></p>
<p><img src="/2019/08/29/Hadoop系列（三）Hadoop三大核心之HDFS-shell常用命令/image-20190830010745946.png" alt="image-20190830010745946"></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop系列（二）Hadoop三个核心之HDFS" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/08/25/Hadoop系列（二）Hadoop三个核心之HDFS/" class="article-date">
      <time datetime="2019-08-25T14:27:28.000Z" itemprop="datePublished">2019-08-25</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/08/25/Hadoop系列（二）Hadoop三个核心之HDFS/">Hadoop系列（二）Hadoop三大核心之HDFS基础</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<p>针对海量数据，核心问题始终是计算和存储。当数据集的大小超过一台独立物理计算机的存储能力时，就有必要对它进行分区并存储到多台机器上。跨机器存储的文件系统就被成为分布式文件系统。分布式系统架构于网络之上，势必引入网络编程的复杂性，如何实现容忍节点故障但不丢失数据，是HDFS的重要挑战。</p>
<h2 id="hdfs基础"><a href="#hdfs基础" class="headerlink" title="hdfs基础"></a>hdfs基础</h2><p>Hadoop 自带HDFS分布式文件系统：Hadoop Distributed Filesystem。也简称DFS。主要用来解决海量数据的存储问题。</p>
<p>HDFS有以下两点特性</p>
<ul>
<li>文件系统：用于存储文件，通过统一目录树定位</li>
<li>分布式：很多机器共同支撑其功能</li>
</ul>
<h3 id="重要概念"><a href="#重要概念" class="headerlink" title="重要概念"></a>重要概念</h3><h4 id="数据块"><a href="#数据块" class="headerlink" title="数据块"></a>数据块</h4><p>和一般的文件系统一样，HDFS也有块（block）的概念，HDFS上的文件也被划分为块大小的多个分块作为独立的存储单元。</p>
<p>Hadoop 1.x 默认大小为64MB, 2.x和3.x均为128MB。具体指定版本的默认值，可参见官网<a href="http://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Blocks" target="_blank" rel="noopener">块的定义</a>。HDFS的块比磁盘的块大，是为了最小化寻址开销，减少寻址定位所需时间。</p>
<p>与磁盘文件系统不一样的是*<em>HDFS中小于一个块大小的文件不会占据整个块的空间 *</em>例：当一个1MB的文件存储在一个128MB的块中时，文件只使用1MB的磁盘空间，而不是128MB。当一个150M的文件要存储到HDFS中，将会拆分成2个块，大小分别是128M、22M。</p>
<p>设置数据块的好处：</p>
<p>（1）一个文件的大小可以大于集群任意节点磁盘的容量</p>
<p>（2）容易对数据进行备份，提高容错能力，块丢失可快速从其它节点复制</p>
<p>（3）使用抽象块概念而非整个文件作为存储单元，大大简化存储子系统的设计</p>
<p>HDFS集群有两类节点以管理节点-工作节点的方式运行。即NameNode和DataNode。</p>
<h4 id="NameNode（NN）"><a href="#NameNode（NN）" class="headerlink" title="NameNode（NN）"></a>NameNode（NN）</h4><p>文件系统的管理节点。管理文件系统的命名空间，维护着文本系统树及整棵树内所有文件和目录。基于内存存储，在内存中保存着文件系统每个文件和每个数据块的引用关系以及块信息等。文件目录在NameNode重启后，需要重建。</p>
<p>功能：</p>
<ul>
<li>接收客户端读写服务</li>
<li>收集DataNode汇报的Block列表信息</li>
</ul>
<h4 id="DataNode（DN）"><a href="#DataNode（DN）" class="headerlink" title="DataNode（DN）"></a>DataNode（DN）</h4><p>文件系统的工作节点，多个节点共同工作。本地磁盘目录存储数据，文件形式。</p>
<p>功能：</p>
<ul>
<li>文件形式存储数据（Block）</li>
<li>存储Block的元数据信息文件 （md5）</li>
<li>启动时向NameNode汇报block信息</li>
<li>与NameNode保持心跳连接（3s/次）</li>
</ul>
<p>NameNode虽然以内存方式存储，但是NameNode也会在适当时候持久化两类文件到磁盘。</p>
<ul>
<li>fsimage：NameNode启动时对整个文件系统的快照</li>
<li>edit logs：NameNode启动后，对文件系统的改动序列</li>
</ul>
<p><img src="/2019/08/25/Hadoop系列（二）Hadoop三个核心之HDFS/image-20190827232356723.png" alt="image-20190827232356723"></p>
<p>只有在NameNode重启时，edit logs才会合并到fsimage文件中，从而得到一个文件系统的最新快照。但是在产品集群中NameNode是很少重启的，这也意味着当NameNode运行了很长时间后，edit logs文件会变得很大。这会引发以下严重问题：1.edit logs文件会变的很大，不容易管理；2.重启会花费很长时间，因为有很多改动，可能经历好几个小时甚至几十个小时，这是不能容忍的。</p>
<h4 id="Secondary-NameNode-SNN"><a href="#Secondary-NameNode-SNN" class="headerlink" title="Secondary NameNode   (SNN)"></a>Secondary NameNode   (SNN)</h4><p>SecondaryNameNode就是来帮助解决上述问题的，职责是帮助NN合并edits log成fsimage，减少NameNode启动时间</p>
<p>SNN 合并edits触发条件：<br>1.定期触发。默认一小时。<br>2.时间未到的情况，edits log大小超过容量也会触发。默认 64M。</p>
<p>配置文件core-site.xml  可设置时间间隔（fs.checkpoint.period ）和edits log容量（fs.checkpoint.size）。</p>
<p><img src="/2019/08/25/Hadoop系列（二）Hadoop三个核心之HDFS/5D3FAC2F-F9B2-4F08-B5EA-68771B0BA0F8.png" alt="5D3FAC2F-F9B2-4F08-B5EA-68771B0BA0F8"></p>
<h2 id="Hadoop-特点"><a href="#Hadoop-特点" class="headerlink" title="Hadoop 特点"></a>Hadoop 特点</h2><p>HDFS也是按照Master和Slave的结构。分NameNode、SecondaryNameNode、DataNode这几个角色。</p>
<p><img src="/2019/08/25/Hadoop系列（二）Hadoop三个核心之HDFS/1228818-20180308190320147-1328604927.png" alt="img"></p>
<p>因其架构方案，拥有很多特点：<br>        保存多个副本，且提供容错机制，副本丢失或宕机自动恢复（默认存3份）。<br>　　可运行在廉价的机器上<br>　　适合大数据的处理。HDFS默认会将文件分割成block。然后将block按键值对存储在HDFS上，并将键值对的映射存到内存中。</p>
<p>当然HDFS也有其局限性：<br>1.低延时数据访问。在用户交互性的应用中，应用需要在ms或者几个s的时间内得到响应。由于HDFS为高吞吐率做了设计，也因此牺牲了快速响应。对于低延时的应用，可以考虑使用HBase或者Cassandra。<br>2.大量的小文件。标准的HDFS数据块的大小是64M，存储小文件并不会浪费实际的存储空间，但是无疑会增加了在NameNode上的元数据，大量的小文件会影响整个集群的性能。<br>3.多用户写入，修改文件。HDFS的文件只能有一个写入者，而且写操作只能在文件结尾以追加的方式进行。它不支持多个写入者，也不支持在文件写入后，对文件的任意位置的修改。<br>但是在大数据领域，分析的是已经存在的数据，这些数据一旦产生就不会修改，因此，HDFS的这些特性和设计局限也就很容易理解了。HDFS为大数据领域的数据分析，提供了非常重要而且十分基础的文件存储功能。</p>
<h2 id="Hadoop-HA"><a href="#Hadoop-HA" class="headerlink" title="Hadoop HA"></a>Hadoop HA</h2><h4 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h4><ol>
<li>冗余备份<br>每个文件存储成一系列数据块（Block）。为了容错，文件的所有数据块都会有副本（副本数量即复制因子，可配置）（dfs.replication）</li>
<li>副本存放<br>采用机架感知（Rak-aware）的策略来改进数据的可靠性、高可用和网络带宽的利用率</li>
<li>心跳检测<br>NameNode周期性地从集群中的每一个DataNode接受心跳包和块报告，收到心跳包说明该DataNode工作正常</li>
<li>安全模式<br>系统启动时，NameNode会进入一个安全模式。此时不会出现数据块的写操作。</li>
<li>数据完整性检测<br>HDFS客户端软件实现了对HDFS文件内容的校验和（Checksum）检查（dfs.bytes-per-checksum）。</li>
</ol>
<h4 id="单点故障问题"><a href="#单点故障问题" class="headerlink" title="单点故障问题"></a>单点故障问题</h4><p>因为NameNode部署为单点失效，存在单点故障问题，当NameNode，那么客户端或MapReduce作业均无法读写查看文件。注意HDFS已有存储不会丢失。</p>
<p>解决方案：</p>
<p>启动一个拥有文件系统元数据的新NameNode（这个一般不采用，因为复制元数据非常耗时间）<br>配置一对活动-备用（Active-Sandby）NameNode，活动NameNode失效时，备用NameNode立即接管，用户不会有明显中断感觉。<br>　　　　共享编辑日志文件（借助NFS、zookeeper等）<br>　　　　DataNode同时向两个NameNode汇报数据块信息<br>　　　　客户端采用特定机制处理 NameNode失效问题，该机制对用户透明</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop开篇" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/08/24/Hadoop开篇/" class="article-date">
      <time datetime="2019-08-23T16:08:08.000Z" itemprop="datePublished">2019-08-24</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/08/24/Hadoop开篇/">Hadoop系列（一）开篇简介</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<p>谁说大象不会跳舞</p>
<h2 id="Hadoop是什么"><a href="#Hadoop是什么" class="headerlink" title="Hadoop是什么"></a>Hadoop是什么</h2><p>Hadoop的官网：<a href="http://hadoop.apache.org/" target="_blank" rel="noopener">http://hadoop.apache.org/</a></p>
<p>官网定义：The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models.</p>
<p>Hadoop： 适合大数据的分布式存储和计算平台</p>
<p>现为Apache顶级开源项目，Hadoop不是指具体一个框架或者组件，它是Apache软件基金会下用Java语言开发的一个开源分布式计算平台。实现在大量计算机组成的集群中对海量数据进行分布式计算，适合大数据的分布式存储和计算平台。</p>
<p>举个简单例子：假如说你有一个篮子水果，你想知道苹果和梨的数量是多少，那么只要一个一个数就可以知道有多少了。如果你有一个集装箱水果，这时候就需要很多人同时帮你数了，这相当于多进程或多线程。如果你很多个集装箱的水果，这时就需要分布式计算了，也就是Hadoop。Hadoopd之所谓会诞生，主要是由于进入到大数据时代，计算机需要处理的数据量太过庞大。这时就需要将这些庞大数据切割分配到N台计算机进行处理。当大量信息被分配到不同计算机进行处理时，要确保最终得到的结果正确就需要对这些分布处理的信息进行管理，hadoop就是这样的一套解决方案。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>1、Hadoop是Apache旗下的一套开源适合大数据的分布式存储和计算平台平台</p>
<p>2、Hadoop提供的功能：利用服务器集群，根据户自定义业逻辑对海量数进行分布式处理</p>
<p>hadoop的概念：</p>
<p>　　狭义上： 就是apache的一个顶级项目：apahce hadoop</p>
<p>　　广义上: 就是指以hadoop为核心的整个大数据处理体系</p>
<h2 id="Hadoop的起源"><a href="#Hadoop的起源" class="headerlink" title="Hadoop的起源"></a>Hadoop的起源</h2><p>HADOOP最早起源于Nutch。Nutch的设计目标是构建一个大型的全网搜索引擎，为Apache Lucene项目的一部分，包括网页抓取、索引、查询等功能，但随着抓取网页数量的增加，遇到了严重的可扩展性问题——如何解决数十亿网页的存储和索引问题。<br>这个问题的解决方案源于Google的三大论文 ：GFS ，BigTable和MapReduce。受此启发的Doug Cutting（Hadoop之父）等人用业余时间实现了DFS和MapReduce机制。2006年2月从Nutch被分离出来，成为一套完整独立的软件，起名为Hadoop。</p>
<p>Hadoop的成长过程经历了：Lucene–&gt;Nutch—&gt;Hadoop</p>
<p>三篇论文的核心思想逐步演变，最终：</p>
<p>GFS—-&gt;HDFS<br>Google MapReduce—-&gt;Hadoop MapReduce<br>BigTable—-&gt;HBase</p>
<h2 id="Hadoop版本与架构核心"><a href="#Hadoop版本与架构核心" class="headerlink" title="Hadoop版本与架构核心"></a>Hadoop版本与架构核心</h2><p>Apache开源社区版本，现已到3.x </p>
<p>Hadoop1.0版本两个核心：HDFS+MapReduce</p>
<p>Hadoop2.0版本，引入了Yarn。核心：HDFS+Yarn+Mapreduce</p>
<p>​    Yarn是资源调度框架。能够细粒度的管理和调度任务。此外，还能够支持其他的计算框架，比如spark等。</p>
<p><img src="/2019/08/24/Hadoop开篇/1775767-20190824015110535-1305780494-20190824134434478.png" alt="img"></p>
<p>Hadoop3.0版本，未引入新核心，在原核心上，升级了很多东西。具体参见官网</p>
<h4 id="Hadoop的核心组件："><a href="#Hadoop的核心组件：" class="headerlink" title="Hadoop的核心组件："></a>Hadoop的核心组件：</h4><p>　　1）<strong>Hadoop Common</strong>：支持其他Hadoop模块的常用工具。</p>
<p>　　2)  <strong>Hadoop分布式文件系统（HDFS™）</strong>：一种分布式文件系统，可提供对应用程序数据的高吞吐量访问。</p>
<p>　　3)  <strong>Hadoop YARN</strong>：作业调度和集群资源管理的框架。</p>
<p>　　<strong>4)  Hadoop MapReduce</strong>：一种用于并行处理大型数据集的基于YARN的系统。</p>
<p>　　大数据的处理主要就是<strong>存储</strong>和<strong>计算</strong>。</p>
<p>如果说安装hadoop集群，其实就是安装了两个东西： 一个操作系统YARN 和 一个文件系统HDFS。其实MapReduce就是运行在YARN之上的应用。</p>
<p>操作系统 　　文件系统 　　应用程序<br>win7 　　　　NTFS　　　  QQ，WeChat<br>YARN 　　　 HDFS 　　    MapReduce</p>
<h2 id="Hadoop理念"><a href="#Hadoop理念" class="headerlink" title="Hadoop理念"></a>Hadoop理念</h2><p>Hadoop可运行于一般的商用服务器上，具有高容错、高可靠性、高扩展性等特点</p>
<p>特别适合写一次，读多次的场景</p>
<p> 适合场景</p>
<ul>
<li>大规模数据</li>
<li>流式数据（写一次，读多次）</li>
<li>商用硬件（一般硬件）</li>
</ul>
<p>不适合场景</p>
<ul>
<li>低延时的数据访问</li>
<li>大量的小文件</li>
<li>频繁修改文件</li>
</ul>
<h2 id="PS"><a href="#PS" class="headerlink" title="PS"></a>PS</h2><p>Hadoop起源的三个google论文   中文版</p>
<p><a href="http://blog.bizcloudsoft.com/wp-content/uploads/Google-File-System%E4%B8%AD%E6%96%87%E7%89%88_1.0.pdf" target="_blank" rel="noopener">GFS</a>  Google的分布式文件系统Google File System<br><a href="http://blog.bizcloudsoft.com/wp-content/uploads/Google-Bigtable%E4%B8%AD%E6%96%87%E7%89%88_1.0.pdf" target="_blank" rel="noopener">BigTable</a>  一个大型的分布式数据库<br><a href="http://blog.bizcloudsoft.com/wp-content/uploads/Google-MapReduce%E4%B8%AD%E6%96%87%E7%89%88_1.0.pdf" target="_blank" rel="noopener">MapReduce</a> Google的MapReduce开源分布式并行计算框架</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2016-2019 ID喵
            </div>
            <div class="footer-right">
                
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>