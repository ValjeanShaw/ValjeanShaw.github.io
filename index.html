<!DOCTYPE html>
<html lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no">
<meta name="author" content="ID喵">


    
    


<meta property="og:type" content="website">
<meta property="og:title" content="ID喵">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="ID喵">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ID喵">

<link rel="apple-touch-icon" href="/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="ID喵" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">


    <style> .article { opacity: 0;} </style>


<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>ID喵</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: true,
        isPost: false,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: 
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head></html>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/langya.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">ID喵</a></h1>
        </hgroup>

        
        <p class="header-subtitle">喵了个喵，我又遇到瓶颈了...</p>
        

        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/archives/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="/xiaoran737@163.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="https://github.com/ValjeanShaw" title="GitHub"></a>
                            
                                <a class="fa 博客园" href="https://www.cnblogs.com/valjeanshaw/" title="博客园"></a>
                            
                                <a class="fa 掘金" href="https://juejin.im/user/5d5bd7106fb9a06b0c08695f" title="掘金"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/concurrent/">concurrent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分布式/">分布式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分布式-zookeeper/">分布式 zookeeper</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">ID喵</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/langya.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">ID喵</a></h1>
            </hgroup>
            
            <p class="header-subtitle">喵了个喵，我又遇到瓶颈了...</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/archives/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="/xiaoran737@163.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="https://github.com/ValjeanShaw" title="GitHub"></a>
                            
                                <a class="fa 博客园" target="_blank" href="https://www.cnblogs.com/valjeanshaw/" title="博客园"></a>
                            
                                <a class="fa 掘金" target="_blank" href="https://juejin.im/user/5d5bd7106fb9a06b0c08695f" title="掘金"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap">
  
    <article id="post-Zookeeper系列-一-zookeeper的概念" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/11/10/Zookeeper系列-一-zookeeper的概念/" class="article-date">
      <time datetime="2019-11-10T04:41:53.000Z" itemprop="datePublished">2019-11-10</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/11/10/Zookeeper系列-一-zookeeper的概念/">Zookeeper系列 (一) zookeeper的概念</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="zookeeper是什么"><a href="#zookeeper是什么" class="headerlink" title="zookeeper是什么"></a>zookeeper是什么</h2><p>定义：zookeeper是一个开源的分布式协调服务，一个典型的分布式数据一致性解决方案。</p>
<p>前世今生：Yahoo创建，最初为 hadoop的子项目，是google Chubby的开源实现，现为Apache的顶级项目。</p>
<p>分布式应用程序可以基于zookeeper实现数据发布订阅、负载均衡、命名服务、分布式锁、集群管理等一系列功能。</p>
<h2 id="zookeeper提供什么能力"><a href="#zookeeper提供什么能力" class="headerlink" title="zookeeper提供什么能力"></a>zookeeper提供什么能力</h2><p>zookeeper搭建的集群可以保证以下分布式协议</p>
<ol>
<li><p>顺序一致性</p>
<p>从同一个客户端发起的多个事务请求，将会严格按照发起顺序应用到各个节点</p>
</li>
<li><p>原子性</p>
<p>所有事务请求的处理结果在集群中所有机器的应用情况一致。所有机器要么全部应用，要么全部不应用。</p>
</li>
<li><p>单一视图</p>
<p>无论连接的是哪个节点，效果都一样</p>
</li>
<li><p>可靠性</p>
<p>一旦一个事务被应用，那么该事物状态会被保持</p>
</li>
<li><p>实时性</p>
<p>zookeeper保证<strong>一定时间段</strong>后，客户端从服务端读取到最新状态</p>
</li>
</ol>
<h2 id="zookeeper的特点"><a href="#zookeeper的特点" class="headerlink" title="zookeeper的特点"></a>zookeeper的特点</h2><p>###数据模型简单</p>
<p>zk的数据模型是一个共享的、树树型结构的名字空间。由一系列ZNode组成，ZNode被称为数据节点，具有层级关系。<strong>zk将全量数据存储在内存中，以此来实现提高服务器吞吐，减少延迟的目的</strong></p>
<h3 id="可构成集群"><a href="#可构成集群" class="headerlink" title="可构成集群"></a>可构成集群</h3><p>zk集群由一组机器构成，3~5台即可，组成zk集群的每台机器在<strong>内存中维护</strong>当前的服务器状态，并且每台机器之间都互相保持着通信。集群中只要超过一般的机器能正常工作，那整个集群就能正常对外服务</p>
<h3 id="顺序访问"><a href="#顺序访问" class="headerlink" title="顺序访问"></a>顺序访问</h3><p>对于来自客户端的每个更新请求，zk都会分配一个全局唯一的递增编号，事务操作将按照这个编号按照先后顺序执行，且该特性可被实用于其他用途。</p>
<h3 id="高性能"><a href="#高性能" class="headerlink" title="高性能"></a>高性能</h3><p>全量数据都存储在内存中，并直接服务于客户端的所有非事务请求，尤其适合读操作为主的场景。</p>
<h2 id="zookeeper的基本概念"><a href="#zookeeper的基本概念" class="headerlink" title="zookeeper的基本概念"></a>zookeeper的基本概念</h2><p>zk的概念此处只做基本介绍和简单讲解，后续做详细讲解</p>
<h3 id="集群角色"><a href="#集群角色" class="headerlink" title="集群角色"></a>集群角色</h3><ul>
<li>Leader</li>
</ul>
<p>一个，提供读写能力</p>
<ul>
<li>Follower</li>
</ul>
<p>多个，提供读能力，选举Leader能力</p>
<ul>
<li>Observer</li>
</ul>
<p>多个，提供读能力，不参与选举</p>
<h3 id="会话"><a href="#会话" class="headerlink" title="会话"></a>会话</h3><p>zk客户端和服务器之间是TCP长连接。sessionTimeout设置一个会话超时时间，连接异常断开时，只要在超时时间内连接上任意一台zk节点，之前的会话依然有效。</p>
<h3 id="节点"><a href="#节点" class="headerlink" title="节点"></a>节点</h3><h4 id="1-机器节点"><a href="#1-机器节点" class="headerlink" title="1.机器节点"></a>1.机器节点</h4><p>构成集群的机器</p>
<h4 id="2-数据节点-ZNode"><a href="#2-数据节点-ZNode" class="headerlink" title="2.数据节点 ZNode"></a>2.数据节点 ZNode</h4><p>ZNode数据节点，数据模型中的数据单元。数据模型是一棵树，由斜杠（/）分割路径，保存数据内容和属性。可分为持久节点和临时节点两类</p>
<h3 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h3><p>每个ZNode上面都有一个stat的数据结构，记录3个数据版本：</p>
<ol>
<li>version：当前ZNode版本</li>
<li>cversion：当前ZNode子节点的版本</li>
<li>aversion：当前ZNode的ACL版本</li>
</ol>
<h3 id="ACL"><a href="#ACL" class="headerlink" title="ACL"></a>ACL</h3><p>(access control lists) 权限控制清单</p>
<ul>
<li>CREATE: 创建<strong>子节点</strong>权限</li>
<li>READ: 获取节点数据和子节点列表的权限</li>
<li>WRITE: 更新节点数据的权限</li>
<li>DELETE: 删除<strong>子节点</strong>的权限</li>
<li>ADMIN: 设置节点ACL的权限</li>
</ul>
<p>create和delete都是针对子节点的权限控制</p>
<h3 id="Watcher"><a href="#Watcher" class="headerlink" title="Watcher"></a>Watcher</h3><p>事件监听。zk的重要特性，zk允许用户注册事件到指定节点，当特定时间触发，事件通知会被发送到具体的客户端。</p>
<h3 id><a href="#" class="headerlink" title></a></h3>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/zookeeper/">zookeeper</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/分布式-zookeeper/">分布式 zookeeper</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop系列（九）Hadoop三大核心之Yarn-资源调度详解" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/11/04/Hadoop系列（九）Hadoop三大核心之Yarn-资源调度详解/" class="article-date">
      <time datetime="2019-11-04T06:47:47.000Z" itemprop="datePublished">2019-11-04</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/11/04/Hadoop系列（九）Hadoop三大核心之Yarn-资源调度详解/">Hadoop系列（九）Hadoop三大核心之Yarn-资源调度详解</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="Yarn的调度流程详解"><a href="#Yarn的调度流程详解" class="headerlink" title="Yarn的调度流程详解"></a>Yarn的调度流程详解</h2><p><img src="/2019/11/04/Hadoop系列（九）Hadoop三大核心之Yarn-资源调度详解/image-20191104160107191.png" alt="image-20191104160107191"></p>
<ol>
<li><p>Client端提交作业到ResourceManager中的ApplicationManager，申请JobID（唯一ID）</p>
</li>
<li><p>RM返回一个作业ID，并且将一个临时hdfs路径返回给 Client，要求Client将要上传的文件发送到这个临时目录中。（任务结束后，该临时目录将被删除）</p>
</li>
<li><p>Client将作业运行所需要的资源（jar包、配置文件和分片信息等）向指定的HDFS路径上传</p>
</li>
<li><p>上传成功后，向RM中的AM发送请求，执行作业</p>
</li>
<li><p>AM将请求转发给调度器，调度器开始处理请求</p>
</li>
<li><p>调度器将任务放置队列中，当执行到请求的时候，则告知ApplicationManager 可以分配容器，告知NodeManager的信息用于开辟Container</p>
</li>
<li><p>ApplicationManager命令NodeManager创建一个Container并运行作业的ApplicationMaster。NodeManager创建一个Container并启动作业的ApplicationMaster。<strong>ApplicationMaster将自己注册到ApplicationManager，使得ApplicationManager可以监控到Job的执行状态，Client也可以通过ApplicationManager对作业进行控制。</strong></p>
</li>
<li><p>ApplicationMaster查询临时hdfs路径，获取jar包信息，配置文件等，创建map和reduce任务</p>
</li>
<li><p>ApplicationMaster请求调度器分配资源，开辟map，reduce任务资源</p>
</li>
<li><p>调度器返回执行信息，内含在哪些NodeManager可开辟资源信息</p>
</li>
<li><p>ApplicationMaster通知NodeManager开辟资源池启动map和reduce任务</p>
</li>
<li><p>NodeManager 启动自身资源池中的任务</p>
</li>
<li><p>map、reduce任务查询临时hdfs路径的数据。开始执行。<strong>ApplicationMaster实时监控自己管理的map、reduce任务执行情况，如果失败，请求调度器在新节点中开辟资源池，执行失败的程序。ApplicationManager实时监控自己管理的ApplicationMaster执行情况，如果ApplicationMaster 宕机，创建一个新的ApplicationMaster，继续监控原有的map和reduce任务，在此期间，map、reduce任务不受影响</strong></p>
</li>
<li><p>程序成功，释放资源</p>
</li>
</ol>
<h2 id="Yarn的调度策略"><a href="#Yarn的调度策略" class="headerlink" title="Yarn的调度策略"></a>Yarn的调度策略</h2><ul>
<li>FIFO调度</li>
<li>容量调度</li>
<li>公平调度</li>
</ul>
<h3 id="1-FIFO先进先出调度"><a href="#1-FIFO先进先出调度" class="headerlink" title="1.FIFO先进先出调度"></a>1.FIFO先进先出调度</h3><p>这种调度最简单，将应用放置在一个队列中，然后按照提交的顺序将所有的Applications放到队列中，<strong>先按照作业的优先级高低、再按照到达时间的先后</strong>，为每个app分配资源。如果第一个app需要的资源被满足了，如果还剩下了资源并且满足第二个app需要的资源，那么就为第二个app分配资源。</p>
<p>优点：简单，不需要配置。</p>
<p>缺点：不适合共享集群。如果有大的app需要很多资源，那么其他app可能会一直等待。</p>
<p><img src="/2019/11/04/Hadoop系列（九）Hadoop三大核心之Yarn-资源调度详解/image-20191107004016198.png" alt="image-20191107004016198"></p>
<h3 id="2-Capacity-容量调度机制"><a href="#2-Capacity-容量调度机制" class="headerlink" title="2.Capacity 容量调度机制"></a>2.Capacity 容量调度机制</h3><p>容量调度机制适用于一个集群（集群被多个组织共享）中运行多个Application的情况，目标是最大化吞吐量和集群利用率。</p>
<p>容量调度允许将整个集群的资源分成多个部分，每个组织使用其中的一部分，即每个组织有一个专门的队列，每个组织的队列还可以进一步划分成层次结构（<strong>Hierarchical Queues</strong>），从而允许组织内部的不同用户组的使用。</p>
<p>每个队列内部，按照FIFO的方式调度Applications。当某个队列的资源空闲时，可以将它的剩余资源共享给其他队列。</p>
<p><img src="/2019/11/04/Hadoop系列（九）Hadoop三大核心之Yarn-资源调度详解/image-20191107004427447.png" alt="image-20191107004427447"></p>
<p>实例：</p>
<p>有一个专门的队列允许小的apps提交之后能够尽快执行，job1先提交到queueA，并没有占用系统的全部资源（假如job1需要100G内存，但是整个集群只有100G内存，那么只分配给job1  80G），job2可提交到queueB 中快速执行。</p>
<h3 id="3-Fair-公平调度机制"><a href="#3-Fair-公平调度机制" class="headerlink" title="3.Fair 公平调度机制"></a>3.Fair 公平调度机制</h3><p><strong>FairScheduler</strong>允许应用在一个集群中公平地共享资源。默认情况下FairScheduler的公平调度只基于内存，也可以配置成基于memory &amp; CPU。当集群中只有一个app时，它独占集群资源。当有新的app提交时，空闲的资源被新的app使用，这样最终每个app就会得到大约相同的资源。可以为不同的app设置优先级，决定每个app占用的资源百分比。FairScheduler可以让短的作业在合理的时间内完成，而不必一直等待长作业的完成。</p>
<p><strong>Fair Sharing</strong>： Scheduler将apps组织成queues，将资源在这些queues之间公平分配。默认情况下，所有的apps都加入到名字为“default“的队列中。app也可以指定要加入哪个队列中。队列内部的默认调度策略是基于内存的共享策略，也可以配置成FIFO和multi-resource with Dominant Resource Fairness</p>
<p><strong>Minimum Sharing</strong>：FairScheduller提供公平共享，还允许指定minimum shares to queues，从而保证所有的用户以及Apps都能得到足够的资源。如果有的app用不了指定的minimum的资源，那么可以将超出的资源分给别的app使用。</p>
<p>FairScheduler默认让所有的apps都运行，但是也可以通过配置文件配置每个queue中的分配权重，若权重1：1，当两个queue同时执行任务时，各分到一半资源。</p>
<p><img src="/2019/11/04/Hadoop系列（九）Hadoop三大核心之Yarn-资源调度详解/image-20191107005019943.png" alt="image-20191107005019943"></p>
<p>实例：</p>
<p>两个用户A和B。A提交job1时集群内没有正在运行的app，因此job1独占集群中的资源。用户B的job2提交时，job2在job1释放一半的containers之后，开始执行。job2还没执行完的时候，用户B提交了job3，job2释放它占用的一半containers之后，job3获得资源开始执行。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop系列（八）Hadoop三大核心之Yarn-资源调度初探" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/10/23/Hadoop系列（八）Hadoop三大核心之Yarn-资源调度初探/" class="article-date">
      <time datetime="2019-10-23T11:59:08.000Z" itemprop="datePublished">2019-10-23</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/10/23/Hadoop系列（八）Hadoop三大核心之Yarn-资源调度初探/">Hadoop系列（八）Hadoop三大核心之Yarn 资源调度初探</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="0-Yarn的来源"><a href="#0-Yarn的来源" class="headerlink" title="0. Yarn的来源"></a>0. Yarn的来源</h2><p>​    hadoop 1.x的时代，并没有Yarn，hadoop核心组件只有HDFS和MapReduce。到了hadoop2.x才有了Yarn的诞生，组件包含HDFS，MapReduce和Yarn。</p>
<p>​    诞生原因：hadoop 1.x存在的最大问题就是资源管理问题。技术的发展不再满足于hadoop集群中只使用MapReduce一个计算框架，人们更希望有一套合理的管理机制，来控制集群的资源管理问题。就此Yarn诞生。</p>
<h2 id="1-YARN概述"><a href="#1-YARN概述" class="headerlink" title="1. YARN概述"></a>1. YARN概述</h2><p>全称 Yet Another Resource Negotiator。是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而 MapReduce，spark 等运算程序可以运行在YARN上，相当于应用程序运行于操作系统之上</p>
<p>YARN 是 Hadoop2.x 版本中的一个新特性。它的出现是为了解决第一代 MapReduce 编程框架的不足，提高集群环境下的资源利用率，这些资源包括内存，磁盘，网络，IO等。Hadoop2.X 版本中重新设计的这个 YARN 集群，具有更好的扩展性，可用性，可靠性，向后兼容性，以及能支持除 MapReduce 以外的更多分布式计算程序</p>
<p>YARN的特点：</p>
<ol>
<li>YARN不清楚提交的程序的运行机制</li>
<li>只提供运算资源的调度，分配。用户申请就分配。</li>
<li>与运行的用户程序完全解耦。 YARN 上可以运行各种类型的分布式运算程序。比如 MapReduce、Storm 程序，Spark 程序等</li>
<li>yarn 是一个通用的资源调度平台，企业中存在的各种运算集群都可以整合在一个物理集群上，提高资源利用率，方便数据共享</li>
</ol>
<p>Yarn最大的特点是执行调度与Hadoop上运行的任务类型无关</p>
<h2 id="2-YARN的重要组成部分"><a href="#2-YARN的重要组成部分" class="headerlink" title="2. YARN的重要组成部分"></a>2. YARN的重要组成部分</h2><p>有两类长期运行的守护进程提供核心服务</p>
<ul>
<li>ResourceManager(主节点) ：全局资源管理器</li>
<li>NodeManager(从节点)：节点资源管理器</li>
</ul>
<p>主从结构如图</p>
<p><img src="/2019/10/23/Hadoop系列（八）Hadoop三大核心之Yarn-资源调度初探/image-20191103184844628.png" alt="image-20191103184844628"></p>
<h3 id="2-1-ResourceManager"><a href="#2-1-ResourceManager" class="headerlink" title="2.1 ResourceManager"></a>2.1 ResourceManager</h3><p>RM组件是负责资源管理的，整个系统有且只有一个 RM ，来负责资源的调度。ResourceManager 会为每一个 Application 启动一个 ApplicationMaster， 并且 ApplicationMaster 分散在各个 NodeManager 节点</p>
<p>RM里面还有两个重要组成部分：</p>
<ol>
<li>应用程序管理器  Application Manager</li>
<li>资源调度器          Resource Scheduler</li>
</ol>
<p>ResourceManager名字就是这两个词合并而来</p>
<h4 id="Application-Manager-应用程序管理器"><a href="#Application-Manager-应用程序管理器" class="headerlink" title="Application Manager   应用程序管理器"></a>Application Manager   应用程序管理器</h4><p>应用程序管理器就是负责管理 Client 用户提交的应用的管理器</p>
<p>主要功能：</p>
<ol>
<li><p>负责接收client端传输的job请求，为应用(MapReduce 程序)分配一个Container（资源池）来运行一个Application Master</p>
</li>
<li><p>负责监控<strong>Appication Master</strong></p>
</li>
<li><p>并且在遇到失败的时候重启Application Master</p>
</li>
</ol>
<h4 id="Scheduler-资源调度器"><a href="#Scheduler-资源调度器" class="headerlink" title="Scheduler   资源调度器"></a>Scheduler   资源调度器</h4><p>Resource Scheduler即资源调度器，是让每一个节点都充分利用起来，合理分配和调度资源的一种管理器。</p>
<p>值得注意的是：调度器真的只是一个调度器，不参与任何具体的和应用程序相关的工作。</p>
<h3 id="2-2-NodeManager"><a href="#2-2-NodeManager" class="headerlink" title="2.2 NodeManager"></a>2.2 NodeManager</h3><p>NodeManager 是 YARN 集群当中真正资源的提供者，是真正执行应用程序的容器的提供者， 监控应用程序的资源使用情况（CPU，内存，硬盘，网络），并通过心跳向集群资源调度器 ResourceManager 进行汇报以更新自己的健康状态。同时其也会监督 Container 的生命周期管理，监控每个 Container 的资源使用（内存、CPU 等）情况，追踪节点健康状况，管理日 志和不同应用程序用到的附属服务（auxiliary service）。</p>
<h3 id="2-3-逻辑上的组件Application-Master"><a href="#2-3-逻辑上的组件Application-Master" class="headerlink" title="2.3 逻辑上的组件Application Master"></a>2.3 逻辑上的组件Application Master</h3><p>ApplicationMaster 就是一个java程序，进程名：MRAppMaster</p>
<p>作用：负责监控Map、Reduce任务。用户提交的每一个程序都会产生一个ApplicationMaster，这个AM就是负责整个任务的一个管理者，由这个 AM去向ResourceManager 申请容器资源，获得资源后会将要运行的程序发送到容器上启动，然后进行分布式计算。</p>
<p>主要功能：</p>
<ol>
<li>与调度器（Scheduler）协商，获取执行资源</li>
<li>与NodeManager通信，启动任务和停止任务</li>
<li>监控所有旗下Job的执行状态，重启失败任务</li>
</ol>
<h2 id="3-Container-资源池"><a href="#3-Container-资源池" class="headerlink" title="3. Container  资源池"></a>3. Container  资源池</h2><p>Yarn中的资源抽象，封装了多维度资源： 内存，cpu，磁盘等。Container就是Scheduler进行资源分配的一个单位，也是运行各个任务的容器。</p>
<ul>
<li>容器由 NodeManager 启动和管理，并被它所监控。</li>
<li>容器被 ResourceManager 进行调度。</li>
</ul>
<p><img src="/2019/10/23/Hadoop系列（八）Hadoop三大核心之Yarn-资源调度初探/image-20191104135136097.png" alt="image-20191104135136097"></p>
<h2 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a>4. 小结</h2><p>Yarn是Hadoop2.x之后引入的新组件。Yarn的架构采用了主从结构，一主多从（ResourceManager &amp; NodeManager）。Yarn在Hadoop中的功能作用有两个，第一是负责Hadoop集群中的资源管理(resource management)，第二是负责对任务进行调度和监控(scheduling/monitoring)。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop系列（七）Hadoop三大核心之MapReduce-程序编写" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/10/14/Hadoop系列（七）Hadoop三大核心之MapReduce-程序编写/" class="article-date">
      <time datetime="2019-10-14T12:17:40.000Z" itemprop="datePublished">2019-10-14</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/10/14/Hadoop系列（七）Hadoop三大核心之MapReduce-程序编写/">Hadoop系列（七）Hadoop三大核心之MapReduce-程序编写</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<p>接下来以一个简单的WordCount为例子，介绍Java版本的MapReduce的程序编写。</p>
<p>mapreduce程序主要分三部分：1.map部分，2.reduce部分，3.提交部分。</p>
<h3 id="1-准备部分"><a href="#1-准备部分" class="headerlink" title="1. 准备部分"></a>1. 准备部分</h3><p>hadoop中，针对数据类型自成一体，与java的数据类型对应。封装在hadoop.io包中，主要分为基本类型和其它类型。</p>
<ul>
<li>基本数据类型</li>
</ul>
<table>
<thead>
<tr>
<th>数据类型</th>
<th>hadoop数据类型</th>
<th>Java数据类型</th>
</tr>
</thead>
<tbody><tr>
<td>布尔</td>
<td>BooleanWritable</td>
<td>boolean</td>
</tr>
<tr>
<td>整型</td>
<td>IntWritable</td>
<td>int</td>
</tr>
<tr>
<td>长整型</td>
<td>LongWritable</td>
<td>long</td>
</tr>
<tr>
<td>浮点型</td>
<td>FloatWritable</td>
<td>float</td>
</tr>
<tr>
<td>双精浮点</td>
<td>DoubleWritable</td>
<td>double</td>
</tr>
<tr>
<td>字节</td>
<td>ByteWritable</td>
<td>byte</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<ul>
<li>其它类型</li>
</ul>
<table>
<thead>
<tr>
<th>数据类型</th>
<th>hadoop数据类型</th>
<th>Java数据类型</th>
</tr>
</thead>
<tbody><tr>
<td>字符串</td>
<td>Text</td>
<td>String</td>
</tr>
<tr>
<td>数组</td>
<td>ArrayWritable</td>
<td>Array</td>
</tr>
<tr>
<td>Map</td>
<td>MapWritable</td>
<td>Map</td>
</tr>
</tbody></table>
<h3 id="2-jar包依赖"><a href="#2-jar包依赖" class="headerlink" title="2. jar包依赖"></a>2. jar包依赖</h3><p>创建一个maven工程，pom.xml文件中，添加以下依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="3-Map部分"><a href="#3-Map部分" class="headerlink" title="3. Map部分"></a>3. Map部分</h3><p>映射部分，将数据逐条处理</p>
<p>首先，需要继承Mapper&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;类</p>
<p>四个泛型参数分别代表：输入key  输入value   输出key   输出value</p>
<p>然后重写mapper的map方法</p>
<figure class="highlight plain"><figcaption><span>key, VALUEIN value, Context context) throws IOException, InterruptedException```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">主体代码:</span><br><span class="line"></span><br><span class="line">```java</span><br><span class="line">public class WordCountMap extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     *  流程，输入key和value，map的结果写入到context中</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">        //读取一行数据</span><br><span class="line">        String line = value.toString();</span><br><span class="line">        //因为英文字母是以“ ”为间隔的，因此使用“ ”分隔符将一行数据切成多个单词并存在数组中</span><br><span class="line">        String str[] = line.split(&quot; &quot;);</span><br><span class="line">        //循环迭代字符串，将一个单词变成&lt;key,value&gt;形式，及&lt;&quot;hello&quot;,1&gt;</span><br><span class="line">        for (String s : str) &#123;</span><br><span class="line">            context.write(new Text(s), new IntWritable(1));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-Reduce部分"><a href="#4-Reduce部分" class="headerlink" title="4.Reduce部分"></a>4.Reduce部分</h3><p>归并部分，将map处理和shuffle之后的数据进行归并。shuffle过程由hadoop控制</p>
<p>Reducer&lt;KEYIN,VALUEIN,KEYOUT,VALUEOUT&gt;</p>
<p>四个泛型参数分别代表：输入key  输入value   输出key   输出value</p>
<p>然后重写reducer的reduce方法</p>
<figure class="highlight plain"><figcaption><span>key, Iterable<valuein> values, Context context) throws IOException, InterruptedException```</valuein></span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">主体代码：</span><br><span class="line"></span><br><span class="line">```java</span><br><span class="line">public class WordCountReduce extends Reducer&lt;Text,IntWritable,Text, IntWritable&gt; &#123;</span><br><span class="line">    /**</span><br><span class="line">     *  流程，输入key和value，map的结果写入到context中</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public void reduce(Text key, Iterable&lt;IntWritable&gt; values,Context context)throws IOException,InterruptedException&#123;</span><br><span class="line">        int count = 0;</span><br><span class="line"></span><br><span class="line">        for(IntWritable value: values) &#123;</span><br><span class="line">            count++;</span><br><span class="line">        &#125;</span><br><span class="line">        context.write(key,new IntWritable(count));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-提交部分"><a href="#5-提交部分" class="headerlink" title="5.提交部分"></a>5.提交部分</h3><p>mapreduce的入口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    <span class="comment">// 构造一个job对象来封装本mapreduce业务到所有信息</span></span><br><span class="line">    Job mrJob = Job.getInstance(conf);</span><br><span class="line">    <span class="comment">// 指定本job工作用到的jar包位置</span></span><br><span class="line">    mrJob.setJarByClass(WordCount.class);</span><br><span class="line">    <span class="comment">// 指定本job用到的mapper类</span></span><br><span class="line">    mrJob.setMapperClass(WordCountMap.class);</span><br><span class="line">    <span class="comment">// 指定本job用到的reducer类</span></span><br><span class="line">    mrJob.setReducerClass(WordCountReduce.class);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 指定mapper输出的kv类型</span></span><br><span class="line">    mrJob.setMapOutputKeyClass(Text.class);</span><br><span class="line">    mrJob.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 指定reducer输出到kv数据类型（setOutputKeyClass 会对mapper和reducer都起作用,如果上面mapper不设置的话）</span></span><br><span class="line">    mrJob.setOutputKeyClass(Text.class);</span><br><span class="line">    mrJob.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    FileInputFormat.addInputPath(mrJob,<span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//设置mapreduce程序的输出路径，MapReduce的结果都是输入到文件中</span></span><br><span class="line">    FileOutputFormat.setOutputPath(mrJob,<span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 最后提交任务</span></span><br><span class="line">    <span class="keyword">boolean</span> waitForCompletion = mrJob.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">    System.exit(waitForCompletion ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="6-打包提交"><a href="#6-打包提交" class="headerlink" title="6.打包提交"></a>6.打包提交</h3><p>将程序打成jar包，提交到hadoop集群中，然后使用命令行进行任务提交</p>
<p>对于输入输出路径，均可接受本地路径和hdfs路径。</p>
<p>本地路径前缀：file://</p>
<p>hdfs路径前缀：hdfs://</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/hadoop-3.1.2/bin/hadoop jar my_mapreduce-1.0-SNAPSHOT.jar com.breakthrough.wordcount.WordCount file:///home/hadoop/english.txt file:///home/hadoop/output</span><br></pre></td></tr></table></figure>


      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop系列（六）Hadoop三大核心之MapReduce-基础" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/10/01/Hadoop系列（六）Hadoop三大核心之MapReduce-基础/" class="article-date">
      <time datetime="2019-10-01T08:51:48.000Z" itemprop="datePublished">2019-10-01</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/10/01/Hadoop系列（六）Hadoop三大核心之MapReduce-基础/">Hadoop系列（六）Hadoop三大核心之MapReduce 基础</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="MapReduce背景"><a href="#MapReduce背景" class="headerlink" title="MapReduce背景"></a>MapReduce背景</h2><p>　　在程序由单机版扩成分布式版时，会引入大量的复杂工作。为了提高开发效率，可以将分布式程序中的公共功能封装成框架，让开发人员可以将精力集中于业务逻辑。Hadoop 当中的 MapReduce 就是这样的一个分布式程序运算框架。</p>
<h2 id="MapReduce是什么"><a href="#MapReduce是什么" class="headerlink" title="MapReduce是什么"></a>MapReduce是什么</h2><p><strong>MapReduce是一个分布式运算程序的编程框架，是用户开发“基于 Hadoop 的数据分析应用” 的核心框架。</strong></p>
<p><strong>核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上。</strong></p>
<p><strong>MapReduce将整个并行计算过程抽象到两个函数：</strong></p>
<p>　　Map（映射）：对一些独立元素组成的列表的每一个元素进行制定的操作，可以高度并行。</p>
<p>　　Reduce（归约）：归约过程，把若干组映射结果进行汇总并输出。</p>
<p><strong>一个简单的MapReduce程序只需要指定Map()、reduce()、input和output，剩下的事情由框架完成。</strong></p>
<p>基于MapReduce写出来的应用程序能够运行在大型集群上，并以一种可靠容错的方式并行处理上T级别的数据集。一个Map/Reduce 作业<em>通常会把输入的数据集切分为若干独立的数据块，由 *map任务（task）</em>以完全并行的方式处理它们。框架会对map的输出先进行排序， 然后把结果输入给<em>reduce任务</em>。通常作业的输入和输出都会被存储在文件系统中。 整个框架负责任务的调度和监控，以及重新执行已经失败的任务。</p>
<h2 id="MapReduce的架构简单介绍"><a href="#MapReduce的架构简单介绍" class="headerlink" title="MapReduce的架构简单介绍"></a>MapReduce的架构简单介绍</h2><p><img src="/2019/10/01/Hadoop系列（六）Hadoop三大核心之MapReduce-基础/image-20191012085953019.png" alt="image-20191012085953019"></p>
<p>Input：输入文件的存储位置。可以是hdfs文件位置，也可以是本地文件位置</p>
<p>Map阶段:自己编写映射逻辑</p>
<p>Shuffle阶段:是我们不需要编写的模块，但却是十分关键的模块。Shuffle 阶段需要从所有 map主机上把相同的 key 的 key value对组合在一起，传给 reduce主机, 作为输入进入 reduce函数里。</p>
<p>Reduce阶段:自己编写合并逻辑</p>
<p>Final result: 最终结果存储在hdfs</p>
<p>MapReduce 更深层次分析后续讲解</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-分布式系列-二-一致性协议 2PC和3PC" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/19/分布式系列-二-一致性协议 2PC和3PC/" class="article-date">
      <time datetime="2019-09-19T12:00:40.000Z" itemprop="datePublished">2019-09-19</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/19/分布式系列-二-一致性协议 2PC和3PC/">分布式系列 (二) 一致性协议 2PC和3PC</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<p>为解决分布式问题，涌现了一大批经典的一致性协议和算法。最著名的就是2PC，3PC，和Paxos算法。</p>
<h2 id="2PC和3PC"><a href="#2PC和3PC" class="headerlink" title="2PC和3PC"></a>2PC和3PC</h2><p>当一个事务操作需要跨越多个分布式节点的时候，为保持事务处理的ACID特性，需要引入一个<strong>协调者</strong>来统一调度所有分布式节点的执行逻辑，这些被调度的分布式节点被称为<strong>参与者</strong>。协调者负责调度参与者的行为，并最终决定这些参与者是否要把事务真正提交。由此衍生出2pc和3pc</p>
<h3 id="2PC-二阶段提交协议"><a href="#2PC-二阶段提交协议" class="headerlink" title="2PC 二阶段提交协议"></a>2PC 二阶段提交协议</h3><p>二阶段提交协议是把事务的提交过程分成两个阶段处理。</p>
<ul>
<li>阶段一：提交事务请求</li>
<li>阶段二：执行事务提交</li>
</ul>
<p><strong>二阶段提交的核心思想就是对每一个事务都采用先尝试后提交的处理方式，因此也可以将二阶段提交看作是一个强一致性算法。</strong></p>
<p>阶段1中，协调者发起一个提议，分别问询各参与者是否接受</p>
<p>![image-20190922233819996](分布式系列-二-一致性协议 2PC和3PC/image-20190922233819996.png)</p>
<p>在阶段2中，协调者根据参与者的反馈，提交或中止事务，如果参与者全部同意则提交，只要有一个参与者不同意就中止。</p>
<p>![image-20190922233839319](分布式系列-二-一致性协议 2PC和3PC/image-20190922233839319.png)</p>
<p>二阶段提交有几个优点：原理简单，容易实现。</p>
<p>二阶段提交有几个<strong>缺点：</strong></p>
<ul>
<li><strong>同步阻塞问题</strong>。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。</li>
<li><strong>单点故障</strong>。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）</li>
<li><strong>数据不一致</strong>。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。</li>
<li><strong>二阶段无法解决的问题</strong>：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。</li>
</ul>
<h3 id="3PC-三阶段提交协议"><a href="#3PC-三阶段提交协议" class="headerlink" title="3PC 三阶段提交协议"></a>3PC 三阶段提交协议</h3><p>三阶段提交（3PC），是二阶段提交（2PC）的改进。有两个改动点。</p>
<ul>
<li>引入超时机制。同时在协调者和参与者中都引入超时机制。</li>
<li>在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。</li>
</ul>
<p>三阶段提交有以下3个阶段：</p>
<ul>
<li><p>阶段一：CanCommit。</p>
<p>事务询问，参与者响应。协调者询问是否可以进行事务操作，参与者反馈</p>
</li>
<li><p>阶段二：PreCommit。</p>
<p>两种可能。</p>
<p>1.协调者获得的所有反馈都是Yes，执行事务的预执行。</p>
<ul>
<li><strong>发送预提交请求</strong> 协调者向参与者发送PreCommit请求，并进入Prepared阶段。</li>
<li><strong>事务预提交</strong> 参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。</li>
<li><strong>响应反馈</strong> 如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。</li>
</ul>
<p>2.任一个参与者向协调者发送了No，或等待超时。执行事务的中断。</p>
<ul>
<li>发送中断请求 协调者向所有参与者发送abort请求。</li>
<li>中断事务 参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。</li>
</ul>
</li>
<li><p>阶段三：doCommit</p>
<p>该阶段进行真正的事务提交，也分两种情况。</p>
<p><strong>1.执行提交</strong></p>
<ul>
<li><strong>发送提交请求</strong> 协调者收到所有Ack响应，将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。</li>
<li><strong>事务提交</strong> 参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。</li>
<li><strong>响应反馈</strong> 事务提交完之后，向协调者发送Ack响应。</li>
<li><strong>完成事务</strong> 协调者接收到所有参与者的Ack响应之后，完成事务。</li>
</ul>
<p><strong>2.中断事务</strong></p>
<p>协调者没有<strong>完全接收</strong>到所有的Ack响应，执行中断事务。</p>
<ul>
<li>协调者向所有参与者发送abort中断请求</li>
<li>事务回滚。参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。</li>
<li>反馈结果。参与者完成事务回滚之后，向协调者发送Ack消息</li>
<li>中断事务。协调者接收到参与者反馈的Ack消息之后，执行事务的中断。</li>
</ul>
</li>
</ul>
<p>![image-20190923233335948](分布式系列-二-一致性协议 2PC和3PC/image-20190923233335948.png)</p>
<h2 id="2PC和3PC的区别"><a href="#2PC和3PC的区别" class="headerlink" title="2PC和3PC的区别"></a>2PC和3PC的区别</h2><p>相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，参与者会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。</p>
<p>在2PC中一个参与者的状态只有它自己和协调者知晓，假如协调者提议后自身宕机，在协调者备份启用前一个参与者又宕机，其他参与者就会进入既不能回滚、又不能强制commit的阻塞状态，直到参与者宕机恢复。</p>
<p>参与者如果在不同阶段宕机，3PC如何应对：</p>
<ul>
<li><strong>阶段1</strong>: 协调者或协调者备份未收到宕机参与者的vote，直接中止事务；宕机的参与者恢复后，读取logging发现未发出赞成vote，自行中止该次事务</li>
<li><strong>阶段2</strong>: 协调者未收到宕机参与者的precommit ACK，但因为之前已经收到了宕机参与者的赞成反馈(不然也不会进入到阶段2)，协调者进行commit；协调者备份可以通过问询其他参与者获得这些信息，过程同理；宕机的参与者恢复后发现收到precommit或已经发出赞成vote，则自行commit该次事务</li>
<li><strong>阶段3</strong>: 即便协调者或协调者备份未收到宕机参与者t的commit ACK，也结束该次事务；宕机的参与者恢复后发现收到commit或者precommit，也将自行commit该次事务</li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/分布式/">分布式</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/分布式/">分布式</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-分布式系列-一-分布式架构概念" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/09/分布式系列-一-分布式架构概念/" class="article-date">
      <time datetime="2019-09-09T15:13:42.000Z" itemprop="datePublished">2019-09-09</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/09/分布式系列-一-分布式架构概念/">分布式系列 (一) 分布式架构概念</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="集中式系统架构与分布式系统架构"><a href="#集中式系统架构与分布式系统架构" class="headerlink" title="集中式系统架构与分布式系统架构"></a>集中式系统架构与分布式系统架构</h2><p>集中式系统：由卓越性能的大型主机单机组成的计算机系统，称为集中式系统。</p>
<p>特点。单机运算能力强劲，部署结构简单。但是，拥有单点故障，且单机价格昂贵。</p>
<p>分布式系统：一个硬件或者软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。</p>
<p>特点：</p>
<ol>
<li>分布性。多台计算机在空间中任意分布，且分布情况随时变动。</li>
<li>对等性。分布式系统中计算机硬件没有主从之分。</li>
<li>并发性。并发的操作共享资源（分布式系统最大挑战之一）。</li>
<li>缺乏全局时钟。分布式系统中时间的先后，缺乏全局时钟序列控制。</li>
<li>故障总是发生。组成分布式系统的计算机，随时都有可能发生任何形式故障</li>
</ol>
<h2 id="分布式系统架构中的挑战"><a href="#分布式系统架构中的挑战" class="headerlink" title="分布式系统架构中的挑战"></a>分布式系统架构中的挑战</h2><h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>定义：一系列对系统中数据进行访问与更新的操作所组成的一个程序执行单元。狭义上的事务特指数据库事务。</p>
<p>4大特性：ACID</p>
<p>原子性 Atomicity    一致性 Consistency    隔离性Isolation    持久性Durability</p>
<p>原子性指事务必须是一个原子的操作序列单元，只允许出现全部成功执行和全部不执行两个状态。</p>
<p>一致性指事务执行的结果必须是使系统从一个一致性状态变为另一个一致性状态。比如数据库事务中，出现故障事务失败，但是数据写入了部分，此为不一致状态。</p>
<p>隔离性指一个事务的执行不能被其它事务干扰。</p>
<p>持久性指事务一旦提交，对系统的变更是永久性的。比如数据库事务操作完毕，数据持久到磁盘。</p>
<h3 id="分布式事务和数据一致性"><a href="#分布式事务和数据一致性" class="headerlink" title="分布式事务和数据一致性"></a>分布式事务和数据一致性</h3><p>一个分布式事务可看作由多个分布式的操作序列组成，由于在分布式事务中，各个子事务的执行是分散的，因此要实现一种能够保证ACID特性的分布式事务处理系统格外复杂。</p>
<p>举个典型的分布式事务场景：一个跨银行的转账操作涉及调用两个异地的银行服务，其中一个是本地银行提供的取款服务，另一个则是目标银行提供的存款服务，这两个服务本身是无状态并且相互独立的，共同构成了一个完整的分布式事物。如果从本地银行取款成功，但是因为某种原因存款服务失败了，那么就必须回滚到取款之前的状态，否则用户可能会发现自己的钱不翼而飞了。</p>
<h4 id="CAP定理"><a href="#CAP定理" class="headerlink" title="CAP定理"></a>CAP定理</h4><p>一个经典的分布式系统理论。CAP理论：<strong>一个分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容错性（P：Partition tolerance）这三个基本需求，最多只能同时满足其中两项。</strong></p>
<p>C 一致性：一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致的状态</p>
<p>A 可用性：系统提供的服务必须一致处于可用的状态，对于用户的每一个操作请求总是能够在<strong>有限时间</strong>内<strong>返回结果</strong></p>
<p>P 分区容错性：分布式系统在遇到任何网络分区故障的时候，仍然需要能够对外满足一致性和可用性的服务，除非网络环境都发生故障</p>
<table>
<thead>
<tr>
<th align="left">选择</th>
<th><strong>说    明</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left">CA</td>
<td>放弃分区容错性，加强一致性和可用性，其实就是传统的单机数据库的选择</td>
</tr>
<tr>
<td align="left">AP</td>
<td>放弃一致性（追求最终一致性），追求分区容错性和可用性，这是很多分布式系统设计时的选择，例如很多NoSQL系统就是如此</td>
</tr>
<tr>
<td align="left">CP</td>
<td>放弃可用性，追求一致性和分区容错性，基本不会选择，网络问题会直接让整个系统不可用</td>
</tr>
</tbody></table>
<p>需要明确的一点是：对于一个分布式系统来说，分区容错性可以说是一个最基本的需求。因为既然是一个分布式系统，那么分布式系统中的组件必然需要部署在不同节点，因此会出现子网络，因此分区容错性成为了一个分布式系统必然要面对和解决的问题。因此系统设计师往往在一致性和可用性之间做平衡取舍。由此引发Base理论。</p>
<h4 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h4><p>BASE是对CAP中一致性和可用性权衡的结果，核心思想是即使无法做到强一致性，但是每个应用都可以根据自身业务特点，采用适当的方式使系统达到最终一致性。</p>
<p>BASE理论三要素：</p>
<ol>
<li>基本可用    Basically Available</li>
<li>软状态    Soft state</li>
<li>最终一致性    Eventually consistent</li>
</ol>
<p>三要素详细解释：</p>
<h5 id="基本可用"><a href="#基本可用" class="headerlink" title="基本可用"></a>基本可用</h5><p>分布式系统出现不可预知故障的时候，允许损失部分可用性</p>
<p>例：集群中部分机器宕机，导致剩余机器压力过大，查询效率从0.5s降到了2s</p>
<h5 id="弱状态"><a href="#弱状态" class="headerlink" title="弱状态"></a>弱状态</h5><p>允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。</p>
<h5 id="最终一致性"><a href="#最终一致性" class="headerlink" title="最终一致性"></a>最终一致性</h5><p>最终一致性强调在系统的所有数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。</p>
<p>总的来说。BASE 理论面向的是大型高可用可扩展的分布式系统，和传统事务的 ACID 是<strong>相反的</strong>，它完全不同于 ACID 的强一致性模型，而是<strong>通过牺牲强一致性</strong>来获得可用性，并允许数据在一段时间是不一致的。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/分布式/">分布式</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/分布式/">分布式</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Hadoop系列（五）Hadoop三大核心之HDFS-读写流程" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/" class="article-date">
      <time datetime="2019-09-08T07:31:34.000Z" itemprop="datePublished">2019-09-08</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/">Hadoop系列（五）Hadoop三大核心之HDFS 读写流程</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<p>首先，再回顾一下HDFS的架构图</p>
<p><img src="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/image-20190908154045344.png" alt="image-20190908154045344"></p>
<h2 id="HDFS写数据流程"><a href="#HDFS写数据流程" class="headerlink" title="HDFS写数据流程"></a>HDFS写数据流程</h2><p><img src="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/image-20190908154424852.png" alt="image-20190908154424852"></p>
<ol>
<li>客户端发送请求，调用DistributedFileSystem API的create方法去请求namenode，并告诉namenode上传文件的文件名、文件大小、文件拥有者。</li>
<li>namenode根据以上信息算出文件需要切成多少块block，以及block要存放在哪个datanode上，并将这些信息返回给客户端。</li>
<li>客户端调用FSDataInputStream API的write方法首先将其中一个block写在datanode上。</li>
<li>每一个block多个副本（默认3个），由已经上传了block的datanode产生新的线程，按照放置副本规则往其它datanode写副本。（并不是由客户端分别往3个datanode上写3份，这样的优势就是快。）</li>
<li>写完后返回给客户端一个信息，然后客户端在将信息反馈给namenode。更新元数据。</li>
</ol>
<h2 id="HDFS读流程"><a href="#HDFS读流程" class="headerlink" title="HDFS读流程"></a>HDFS读流程</h2><p><img src="/2019/09/08/Hadoop系列（五）Hadoop三大核心之HDFS-读写流程/image-20190908155152510.png" alt="image-20190908155152510"></p>
<ol>
<li>客户端通过调用FileSystem对象中的open()方法来读取需要的数据</li>
<li>DistributedFileSystem会通过RPC协议调用NameNode来查找文件块所在的位置</li>
</ol>
<blockquote>
<p><strong>NameNode只会返回所调用文件中开始的几个块而不是全部返回。对于每个返回的块，都包含块所在的DataNode的地址。随后，这些返回的DataNode会按照Hadoop集群的拓扑结构得出客户端的距离，然后再进行排序。如果客户端本身就是DataNode，那么它就从本地读取文件。</strong>其次，DistributedFileSystem会向客户端返回一个支持定位的输入流对象FSDataInputStream，用于给客户端读取数据。FSDataInputStream包含一个DFSInputStream对象，这个对象来管理DataNode和NameNode之间的IO</p>
</blockquote>
<ol start="3">
<li><p>当以上步骤完成时，客户端便会在这个输入流上调用read()方法</p>
</li>
<li><p>DFSInputStream对象中包含文件开始部分数据块所在的DataNode地址，首先它会连接文件第一个块最近的DataNode，随后在数据流中重复调用read方法，直到这个块读完为止。</p>
</li>
<li><p>当第一个块读取完毕时，DFSInputStream会关闭连接，并查找存储下一个数据块距离客户端最近的DataNode，以上这些步骤对客户端来说都是透明的。</p>
</li>
<li><p>当完成所有块的读取时，客户端则会在DFSInputStream中调用close()方法。</p>
</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-序列化" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/05/序列化/" class="article-date">
      <time datetime="2019-09-05T15:55:22.000Z" itemprop="datePublished">2019-09-05</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/05/序列化/">序列化</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="一、序列化和反序列化的定义和场景"><a href="#一、序列化和反序列化的定义和场景" class="headerlink" title="一、序列化和反序列化的定义和场景"></a>一、序列化和反序列化的定义和场景</h2><p>序列化：将对象写入到IO流中</p>
<p>反序列化：从IO流中恢复对象</p>
<p>序列化机制将实现序列化的Java对象转化为字节数组序列。可以使对象可以脱离程序而独立运行</p>
<p>场景和要求：保存到磁盘；在网络中传输。要保存到磁盘和在远程传输的java对象要求都必须是可序列化的。</p>
<p><img src="/2019/09/05/序列化/image-20190907150807138.png" alt="image-20190907150807138"></p>
<h2 id="二、序列化和反序列化的java实现"><a href="#二、序列化和反序列化的java实现" class="headerlink" title="二、序列化和反序列化的java实现"></a>二、序列化和反序列化的java实现</h2><h3 id="Serializable接口"><a href="#Serializable接口" class="headerlink" title="Serializable接口"></a>Serializable接口</h3><p>一个标记接口，不用实现任何方法。一旦实现了此接口，该类的对象就是可序列化的。</p>
<h4 id="序列化步骤"><a href="#序列化步骤" class="headerlink" title="序列化步骤"></a>序列化步骤</h4><p>1 创建ObjectOutputStream输出流；2 调用ObjectOutputStream对象的writeObject输出可序列化对象。</p>
<p>若对象不是序列化对象，序列化是将抛出 NotSerializableException 异常</p>
<h4 id="反序列化步骤"><a href="#反序列化步骤" class="headerlink" title="反序列化步骤"></a>反序列化步骤</h4><p>1 创建ObjectInputStream输入流；2 调用ObjectInputStream对象的readObject()得到可序列化对象</p>
<p>demo:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">People</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> String city;</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCity</span><span class="params">(String city)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.city = city;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        People people = <span class="keyword">new</span> People();</span><br><span class="line">        people.setCity(<span class="string">"成都"</span>);</span><br><span class="line">        people.setName(<span class="string">"假老练"</span>);</span><br><span class="line">        People people1 = <span class="keyword">new</span> People();</span><br><span class="line">        people1.setCity(<span class="string">"北京"</span>);</span><br><span class="line">        people1.setName(<span class="string">"风车车"</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            FileOutputStream fileOutputStream = <span class="keyword">new</span> FileOutputStream(<span class="string">"object.txt"</span>);</span><br><span class="line">            ObjectOutputStream os = <span class="keyword">new</span> ObjectOutputStream(fileOutputStream);</span><br><span class="line">            os.writeObject(people);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            FileInputStream fileInputStream = <span class="keyword">new</span> FileInputStream(<span class="string">"object.txt"</span>);</span><br><span class="line">            ObjectInputStream os = <span class="keyword">new</span> ObjectInputStream(fileInputStream);</span><br><span class="line">            People peopleResult = (People) os.readObject();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>如果需要序列化的类的属性含有非基本数据类型和String类型，即引用类型，那么该引用类型也比如可序列化</strong>。否则依然会抛出 NotSerializableException 异常</p>
<h4 id="serialVersionUID的作用"><a href="#serialVersionUID的作用" class="headerlink" title="serialVersionUID的作用"></a>serialVersionUID的作用</h4><p>Java 的序列化，通过在运行时判断类的serialVersionUID来验证版本一致性。</p>
<p>在进行反序列化时，JVM 会把传来的字节流中的serialVersionUID与本地相应实体（类）的serialVersionUID进行比较，如果相同就认为是一致的，可以进行反序列化，否则就会出现序列化版本不一致的异常。实测如果id一致，属性发生较小变化，对象也会创建出来，并将属性按属性名对号入座。</p>
<p> 当实现序列化的时候，建议显式定义serialVersionUID，若不显式定义 serialVersionUID 的值，Java 会根据类细节自动生成 serialVersionUID 的值。可能造成以下两个问题。1.如果对类的源代码作了修改，再重新编译，新生成的类文件的serialVersionUID的取值有可能也会发生变化。2.类的serialVersionUID的默认值完全依赖于Java编译器的实现，对于同一个类，用不同的Java编译器编译，也有可能会导致不同的serialVersionUID，即不同机器或不同版本jdk反序列化可能失败。</p>
<p>##总计 </p>
<ol>
<li>序列化是将对象写入到IO字节流，反序列化是从IO字节流中恢复对象</li>
<li>序列化的两个主要作用是用来存储和网络传输</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/">java</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-进程，线程与多核，多cpu之间的关系" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/09/02/进程，线程与多核，多cpu之间的关系/" class="article-date">
      <time datetime="2019-09-02T02:55:41.000Z" itemprop="datePublished">2019-09-02</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/02/进程，线程与多核，多cpu之间的关系/">进程，线程与多核，多cpu之间的关系</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <blockquote>
<p>喵了个喵，我又遇到瓶颈了</p>
</blockquote>
<p>[TOC]</p>
<h2 id="cpu架构和工作原理"><a href="#cpu架构和工作原理" class="headerlink" title="cpu架构和工作原理"></a>cpu架构和工作原理</h2><p>计算机有5大基本组成部分，运算器，控制器，存储器，输入和输出。运算器和控制器封装到一起，加上寄存器组和cpu内部总线构成中央处理器（CPU）。cpu的根本任务，就是执行指令，对计算机来说，都是0，1组成的序列，cpu从逻辑上可以划分为3个模块：控制单元、运算单元和存储单元。这三个部分由cpu总线连接起来。</p>
<p><img src="/2019/09/02/进程，线程与多核，多cpu之间的关系/image-20190902202929616.png" alt="image-20190902202929616"></p>
<p>CPU的运行原理就是：控制单元在时序脉冲的作用下，将指令计数器里所指向的指令地址(这个地址是在内存里的)送到地址总线上去，然后CPU将这个地址里的指令读到指令寄存器进行译码。对于执行指令过程中所需要用到的数据，会将数据地址也送到地址总线，然后CPU把数据读到CPU的内部存储单元(就是内部寄存器)暂存起来，最后命令运算单元对数据进行处理加工。周而复始，一直这样执行下去。</p>
<h2 id="多核cpu和多cpu"><a href="#多核cpu和多cpu" class="headerlink" title="多核cpu和多cpu"></a>多核cpu和多cpu</h2><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>多个物理CPU，CPU通过总线进行通信，效率比较低。</p>
<p><img src="/2019/09/02/进程，线程与多核，多cpu之间的关系/image-20190904121329148.png" alt="image-20190904121329148"></p>
<p>多核CPU，不同的核通过L2 cache进行通信，存储和外设通过总线与CPU通信</p>
<p><img src="/2019/09/02/进程，线程与多核，多cpu之间的关系/image-20190904121349591.png" alt="image-20190904121349591"></p>
<h3 id="cpu的缓存"><a href="#cpu的缓存" class="headerlink" title="cpu的缓存"></a>cpu的缓存</h3><p>CPU缓存是位于CPU与内存之间的临时数据交换器，它的容量比内存小的多但是交换速度却比内存要快得多。CPU缓存一般直接跟CPU芯片集成或位于主板总线互连的独立芯片上。</p>
<p><img src="/2019/09/02/进程，线程与多核，多cpu之间的关系/image-20190905092214302.png" alt="image-20190905092214302"></p>
<p>随着多核CPU的发展，CPU缓存通常分成了三个级别：<code>L1</code>，<code>L2</code>，<code>L3</code>。级别越小越接近CPU，所以速度也更快，同时也代表着容量越小。L1 是最接近CPU的, 它容量最小（例如：<code>32K</code>），速度最快，每个核上都有一个 L1 缓存，L1 缓存每个核上其实有两个 L1 缓存, 一个用于存数据的 L1d Cache（Data Cache），一个用于存指令的 L1i Cache（Instruction Cache）。L2 缓存 更大一些（例如：<code>256K</code>），速度要慢一些, 一般情况下每个核上都有一个独立的L2 缓存; L3 缓存是三级缓存中最大的一级（例如3MB），同时也是最慢的一级, 在同一个CPU插槽之间的核共享一个 L3 缓存。</p>
<p>读取数据过程。就像数据库缓存一样，首先在最快的缓存中找数据，如果缓存没有命中(Cache miss) 则往下一级找, 直到三级缓存都找不到时，向内存要数据。一次次地未命中，代表取数据消耗的时间越长。</p>
<p>计算过程。程序以及数据被加载到主内存；指令和数据被加载到CPU的高速缓；CPU执行指令，把结果写到高速缓存；高速缓存中的数据写回主内存</p>
<h2 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h2><p>进程是程序的一次执行，一个程序有至少一个进程，是<code>资源分配的最小单位</code>，资源分配包括cpu、内存、磁盘IO等。线程是<code>程序执行的最小单位</code>,一个进程有至少一个线程。</p>
<h2 id="进程和线程在多核cpu，多cpu中的运行关系"><a href="#进程和线程在多核cpu，多cpu中的运行关系" class="headerlink" title="进程和线程在多核cpu，多cpu中的运行关系"></a>进程和线程在多核cpu，多cpu中的运行关系</h2><p>多cpu的运行，是针对进程的运行状态来说的；多核cpu的运行，是针对线程的运行状态来说的。</p>
<p>操作系统会拆分CPU为一段段时间的运行片，轮流分配给不同的程序。对于多cpu，多个进程可以并行在多个cpu中计算，当然也会存在进程切换；对于单cpu，多个进程在这个单cpu中是并发运行，根据时间片读取上下文+执行程序+保存上下文。同一个进程同一时间段只能在一个cpu中运行，如果进程数小于cpu数，那么未使用的cpu将会空闲。</p>
<p>对于多核cpu，进程中的多线程并行执行，执行过程中存在线程切换，线程切换开销较小。对于单核cpu，多线程在单cpu中并发执行，根据时间片切换线程。同一个线程同一时间段只能在一个cpu内核中运行，如果线程数小于cpu内核数，那么将有多余的内核空闲。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>1 单CPU中进程只能是并发，多CPU计算机中进程可以并行。</p>
<p>2单CPU单核中线程只能并发，单CPU多核中线程可以并行。</p>
<p>3 无论是并发还是并行，使用者来看，看到的是多进程，多线程。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/concurrent/">concurrent</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2016-2019 ID喵
            </div>
            <div class="footer-right">
                
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>